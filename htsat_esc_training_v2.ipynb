{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on training a HTS-AT model for audio classification on the ESC-50 Dataset\n",
    "\n",
    "Referece: \n",
    "\n",
    "[HTS-AT: A Hierarchical Token-Semantic Audio Transformer for Sound Classification and Detection, ICASSP 2022](https://arxiv.org/abs/2202.00874)\n",
    "\n",
    "Following the HTS-AT's paper, in this tutorial, we would show how to use the HST-AT in the training of the ESC-50 Dataset.\n",
    "\n",
    "The [ESC-50 dataset](https://github.com/karolpiczak/ESC-50) is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification. The dataset consists of 5-second-long recordings organized into 50 semantical classes (with 40 examples per class) loosely arranged into 5 major categories\n",
    "\n",
    "Before running this tutorial, please make sure that you install the below packages by following steps:\n",
    "\n",
    "1. download [the codebase](https://github.com/RetroCirce/HTS-Audio-Transformer), and put this tutorial notebook inside the codebase folder.\n",
    "\n",
    "2. In the github code folder:\n",
    "\n",
    "    > pip install -r requirements.txt\n",
    "\n",
    "3. We do not include the installation of PyTorch in the requirment, since different machines require different vereions of CUDA and Toolkits. So make sure you install the PyTorch from [the official guidance](https://pytorch.org/).\n",
    "\n",
    "4. Install the 'SOX' and the 'ffmpeg', we recommend that you run this code in Linux inside the Conda environment. In that, you can install them by:\n",
    "\n",
    "    > sudo apt install sox\n",
    "    \n",
    "    > conda install -c conda-forge ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:09:48.386975300Z",
     "start_time": "2025-03-31T10:09:48.260512800Z"
    }
   },
   "outputs": [],
   "source": [
    "# import basic packages\n",
    "import os\n",
    "import numpy as np\n",
    "import wget\n",
    "import sys\n",
    "import gdown\n",
    "import zipfile\n",
    "import librosa\n",
    "# in the notebook, we only can use one GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:32.381089800Z",
     "start_time": "2025-03-31T10:10:32.333792400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the workspace and download the needed files\n",
    "\n",
    "def create_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "workspace = \"./workspace\"\n",
    "dataset_path = os.path.join(workspace, \"esc-50\")\n",
    "checkpoint_path = os.path.join(workspace, \"ckpt\")\n",
    "esc_raw_path = os.path.join(dataset_path, 'raw')\n",
    "\n",
    "\n",
    "create_path(workspace)\n",
    "create_path(dataset_path)\n",
    "create_path(checkpoint_path)\n",
    "create_path(esc_raw_path)\n",
    "\n",
    "\n",
    "# download the esc-50 dataset\n",
    "\n",
    "if not os.path.exists(os.path.join(dataset_path, 'ESC-50-master.zip')):\n",
    "    print(\"-------------Downloading ESC-50 Dataset-------------\")\n",
    "    wget.download('https://github.com/karoldvl/ESC-50/archive/master.zip', out=dataset_path)\n",
    "    with zipfile.ZipFile(os.path.join(dataset_path, 'ESC-50-master.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall(esc_raw_path)\n",
    "    print(\"-------------Success-------------\")\n",
    "\n",
    "if not os.path.exists(os.path.join(checkpoint_path,'htsat_audioset_pretrain.ckpt')):\n",
    "    gdown.download(id='1OK8a5XuMVLyeVKF117L8pfxeZYdfSDZv', output=os.path.join(checkpoint_path,'htsat_audioset_pretrain.ckpt'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:32.946632Z",
     "start_time": "2025-03-31T10:10:32.899720500Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:38.133261500Z",
     "start_time": "2025-03-31T10:10:33.402155400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Resample ESC-50-------------\n",
      "-------------Success-------------\n",
      "-------------Build Dataset-------------\n",
      "-------------Success-------------\n"
     ]
    }
   ],
   "source": [
    "# Process ESC-50 Dataset\n",
    "meta_path = os.path.join(esc_raw_path, 'ESC-50-master', 'meta', 'esc50.csv')\n",
    "audio_path = os.path.join(esc_raw_path, 'ESC-50-master', 'audio')\n",
    "resample_path = os.path.join(dataset_path, 'resample')\n",
    "savedata_path = os.path.join(dataset_path, 'esc-50-data.npy')\n",
    "create_path(resample_path)\n",
    "\n",
    "meta = np.loadtxt(meta_path , delimiter=',', dtype='str', skiprows=1)\n",
    "audio_list = os.listdir(audio_path)\n",
    "\n",
    "# resample\n",
    "print(\"-------------Resample ESC-50-------------\")\n",
    "for f in audio_list:\n",
    "    full_f = os.path.join(audio_path, f)\n",
    "    resample_f = os.path.join(resample_path, f)\n",
    "    if not os.path.exists(resample_f):\n",
    "        os.system('sox -V1 ' + full_f + ' -r 32000 ' + resample_f)\n",
    "print(\"-------------Success-------------\")\n",
    "\n",
    "print(\"-------------Build Dataset-------------\")\n",
    "output_dict = [[] for _ in range(5)]\n",
    "for label in meta:\n",
    "    name = label[0]\n",
    "    fold = label[1]\n",
    "    target = label[2]\n",
    "    y, sr = librosa.load(os.path.join(resample_path, name), sr = None)\n",
    "    output_dict[int(fold) - 1].append(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"target\": int(target),\n",
    "            \"waveform\": y\n",
    "        }\n",
    "    )\n",
    "np.save(savedata_path, output_dict)\n",
    "print(\"-------------Success-------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:38.157535600Z",
     "start_time": "2025-03-31T10:10:38.136681400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model package\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "\n",
    "from utils import create_folder, dump_config, process_idc\n",
    "import esc_config as config\n",
    "from sed_model import SEDWrapper, Ensemble_SEDWrapper\n",
    "from data_generator import ESC_Dataset\n",
    "from model.htsat import HTSAT_Swin_Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:39.555736700Z",
     "start_time": "2025-03-31T10:10:39.520558400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# Old data preparation clas\n",
    "class data_prep(pl.LightningDataModule):\n",
    "    def __init__(self, train_dataset, eval_dataset, device_num):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.device_num = device_num\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_sampler = DistributedSampler(self.train_dataset, shuffle = False) if self.device_num > 1 else None\n",
    "        train_loader = DataLoader(\n",
    "            dataset = self.train_dataset,\n",
    "            num_workers = config.num_workers,\n",
    "            batch_size = config.batch_size // self.device_num,\n",
    "            shuffle = False,\n",
    "            sampler = train_sampler\n",
    "        )\n",
    "        return train_loader\n",
    "    def val_dataloader(self):\n",
    "        eval_sampler = DistributedSampler(self.eval_dataset, shuffle = False) if self.device_num > 1 else None\n",
    "        eval_loader = DataLoader(\n",
    "            dataset = self.eval_dataset,\n",
    "            num_workers = config.num_workers,\n",
    "            batch_size = config.batch_size // self.device_num,\n",
    "            shuffle = False,\n",
    "            sampler = eval_sampler\n",
    "        )\n",
    "        return eval_loader\n",
    "    def test_dataloader(self):\n",
    "        test_sampler = DistributedSampler(self.eval_dataset, shuffle = False) if self.device_num > 1 else None\n",
    "        test_loader = DataLoader(\n",
    "            dataset = self.eval_dataset,\n",
    "            num_workers = config.num_workers,\n",
    "            batch_size = config.batch_size // self.device_num,\n",
    "            shuffle = False,\n",
    "            sampler = test_sampler\n",
    "        )\n",
    "        return test_loader\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# New data preparation class\n",
    "class data_prep(pl.LightningDataModule):\n",
    "    def __init__(self, dataset, config, device_num):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset  # Store only a reference\n",
    "        self.config = config\n",
    "        self.device_num = device_num\n",
    "        self.train_dataset = None  # Placeholder, will be initialized later\n",
    "        self.eval_dataset = None\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"This method is called inside Lightning, and it ensures datasets are created properly.\"\"\"\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = ESC_Dataset(\n",
    "                dataset=self.dataset,\n",
    "                config=self.config,\n",
    "                eval_mode=False\n",
    "            )\n",
    "            self.eval_dataset = ESC_Dataset(\n",
    "                dataset=self.dataset,\n",
    "                config=self.config,\n",
    "                eval_mode=True\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_sampler = DistributedSampler(self.train_dataset, shuffle=False) if self.device_num > 1 else None\n",
    "        return DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            num_workers=self.config.num_workers,\n",
    "            batch_size=self.config.batch_size // max(1, self.device_num),\n",
    "            shuffle=False,\n",
    "            sampler=train_sampler\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        eval_sampler = DistributedSampler(self.eval_dataset, shuffle=False) if self.device_num > 1 else None\n",
    "        return DataLoader(\n",
    "            dataset=self.eval_dataset,\n",
    "            num_workers=self.config.num_workers,\n",
    "            batch_size=self.config.batch_size // max(1, self.device_num),\n",
    "            shuffle=False,\n",
    "            sampler=eval_sampler\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_sampler = DistributedSampler(self.eval_dataset, shuffle=False) if self.device_num > 1 else None\n",
    "        return DataLoader(\n",
    "            dataset=self.eval_dataset,\n",
    "            num_workers=self.config.num_workers,\n",
    "            batch_size=self.config.batch_size // max(1, self.device_num),\n",
    "            shuffle=False,\n",
    "            sampler=test_sampler\n",
    "        )\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        \"\"\"Removes unpicklable attributes before multiprocessing starts\"\"\"\n",
    "        for attr in [\"trainer\", \"prepare_data\", \"setup\", \"teardown\"]:\n",
    "            if hasattr(self, attr):\n",
    "                delattr(self, attr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:43.301238100Z",
     "start_time": "2025-03-31T10:10:43.277330100Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:44.826029700Z",
     "start_time": "2025-03-31T10:10:44.092046600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_num: 1\n",
      "each batch size: 64\n",
      "Using ESC\n"
     ]
    }
   ],
   "source": [
    "# Set the workspace\n",
    "device_num = torch.cuda.device_count()\n",
    "print(\"device_num:\", device_num)\n",
    "print(\"each batch size:\", config.batch_size // device_num)\n",
    "\n",
    "full_dataset = np.load(os.path.join(config.dataset_path, \"esc-50-data.npy\"), allow_pickle = True)\n",
    "\n",
    "# set exp folder\n",
    "exp_dir = os.path.join(config.workspace, \"results\", config.exp_name)\n",
    "checkpoint_dir = os.path.join(config.workspace, \"results\", config.exp_name, \"checkpoint\")\n",
    "if not config.debug:\n",
    "    create_folder(os.path.join(config.workspace, \"results\"))\n",
    "    create_folder(exp_dir)\n",
    "    create_folder(checkpoint_dir)\n",
    "    dump_config(config, os.path.join(exp_dir, config.exp_name), False)\n",
    "\n",
    "print(\"Using ESC\")\n",
    "dataset = ESC_Dataset(\n",
    "    dataset = full_dataset,\n",
    "    config = config,\n",
    "    eval_mode = False\n",
    ")\n",
    "eval_dataset = ESC_Dataset(\n",
    "    dataset = full_dataset,\n",
    "    config = config,\n",
    "    eval_mode = True\n",
    ")\n",
    "\n",
    "audioset_data = data_prep(dataset, eval_dataset, device_num)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor = \"acc\",\n",
    "    filename='l-{epoch:d}-{acc:.3f}',\n",
    "    save_top_k = 20,\n",
    "    mode = \"max\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_num: 1\n",
      "each batch size: 64\n"
     ]
    }
   ],
   "source": [
    "device_num = torch.cuda.device_count()\n",
    "print(\"device_num:\", device_num)\n",
    "print(\"each batch size:\", config.batch_size // device_num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:46.472422500Z",
     "start_time": "2025-03-31T10:10:46.454282800Z"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:48.680176800Z",
     "start_time": "2025-03-31T10:10:47.431513800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checkpoint from  ./workspace/ckpt/htsat_audioset_pretrain.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_38252\\265537605.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(config.resume_checkpoint, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# Set the Trainer\n",
    "trainer = pl.Trainer(\n",
    "    deterministic=False,\n",
    "    default_root_dir = checkpoint_dir,\n",
    "    gpus = device_num, \n",
    "    val_check_interval = 1.0,\n",
    "    max_epochs = config.max_epoch,\n",
    "    auto_lr_find = True,    \n",
    "    sync_batchnorm = True,\n",
    "    callbacks = [checkpoint_callback],\n",
    "    accelerator = \"ddp\" if device_num > 1 else None,\n",
    "    num_sanity_val_steps = 0,\n",
    "    resume_from_checkpoint = None, \n",
    "    replace_sampler_ddp = False,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "\n",
    "\n",
    "sed_model = HTSAT_Swin_Transformer(\n",
    "    spec_size=config.htsat_spec_size,\n",
    "    patch_size=config.htsat_patch_size,\n",
    "    in_chans=1,\n",
    "    num_classes=config.classes_num,\n",
    "    window_size=config.htsat_window_size,\n",
    "    config = config,\n",
    "    depths = config.htsat_depth,\n",
    "    embed_dim = config.htsat_dim,\n",
    "    patch_stride=config.htsat_stride,\n",
    "    num_heads=config.htsat_num_head\n",
    ")\n",
    "\n",
    "model = SEDWrapper(\n",
    "    sed_model = sed_model, \n",
    "    config = config,\n",
    "    dataset = dataset\n",
    ")\n",
    "\n",
    "if config.resume_checkpoint is not None:\n",
    "    print(\"Load Checkpoint from \", config.resume_checkpoint)\n",
    "    ckpt = torch.load(config.resume_checkpoint, map_location=\"cpu\")\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.head.weight\")\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.head.bias\")\n",
    "    # finetune on the esc and spv2 dataset\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.tscam_conv.weight\")\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.tscam_conv.bias\")\n",
    "    model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(audioset_data, data_prep))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:51.326717800Z",
     "start_time": "2025-03-31T10:10:51.315683Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prepare_data': <function DataHooks.prepare_data at 0x000001A223161870>, 'setup': <function data_prep.setup at 0x000001A223161B40>, 'teardown': <function DataHooks.teardown at 0x000001A223161BD0>, '_log_hyperparams': False, 'prepare_data_per_node': True, 'allow_zero_length_dataloader_with_multiple_devices': False, '_train_transforms': None, '_val_transforms': None, '_test_transforms': None, '_dims': (), 'trainer': None, '_has_prepared_data': False, '_has_setup_fit': False, '_has_setup_validate': False, '_has_setup_test': False, '_has_setup_predict': False, '_has_teardown_fit': False, '_has_teardown_validate': False, '_has_teardown_test': False, '_has_teardown_predict': False, 'dataset': <data_generator.ESC_Dataset object at 0x000001A21BA1BD00>, 'config': <data_generator.ESC_Dataset object at 0x000001A172F26AA0>, 'device_num': 1, 'train_dataset': None, 'eval_dataset': None}\n"
     ]
    }
   ],
   "source": [
    "print(audioset_data.__dict__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:52.469471200Z",
     "start_time": "2025-03-31T10:10:52.444901400Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot pickle attribute 'prepare_data': Can't pickle <function DataHooks.prepare_data at 0x000001A223161870>: it's not the same object as pytorch_lightning.core.hooks.DataHooks.prepare_data\n",
      "Cannot pickle attribute 'setup': Can't pickle <function data_prep.setup at 0x000001A223161B40>: it's not the same object as __main__.data_prep.setup\n",
      "Cannot pickle attribute 'teardown': Can't pickle <function DataHooks.teardown at 0x000001A223161BD0>: it's not the same object as pytorch_lightning.core.hooks.DataHooks.teardown\n",
      "Cannot pickle attribute 'dataset': cannot pickle 'module' object\n",
      "Cannot pickle attribute 'config': cannot pickle 'module' object\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for key, value in audioset_data.__dict__.items():\n",
    "    try:\n",
    "        pickle.dumps(value)\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot pickle attribute '{key}': {e}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:55.572789800Z",
     "start_time": "2025-03-31T10:10:52.623219900Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:11:02.930856200Z",
     "start_time": "2025-03-31T10:10:55.576194900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | sed_model | HTSAT_Swin_Transformer | 31.3 M\n",
      "-----------------------------------------------------\n",
      "30.2 M    Trainable params\n",
      "1.1 M     Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.301   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, trainer in audioset_data: False\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae70153fdeb54b71bc6c105b055d38ea"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.0055654048919677734,
       "ncols": null,
       "nrows": null,
       "prefix": "Training",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'module' object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 34\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBefore training, trainer in audioset_data:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mhasattr\u001B[39m(audioset_data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainer\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# ðŸš€ Run training\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maudioset_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:740\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001B[0m\n\u001B[0;32m    735\u001B[0m     rank_zero_deprecation(\n\u001B[0;32m    736\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    737\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    738\u001B[0m     )\n\u001B[0;32m    739\u001B[0m     train_dataloaders \u001B[38;5;241m=\u001B[39m train_dataloader\n\u001B[1;32m--> 740\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    742\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:685\u001B[0m, in \u001B[0;36mTrainer._call_and_handle_interrupt\u001B[1;34m(self, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    676\u001B[0m \u001B[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;124;03mas all errors should funnel through them\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 685\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    686\u001B[0m \u001B[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001B[39;00m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:777\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;66;03m# TODO: ckpt_path only in v1.7\u001B[39;00m\n\u001B[0;32m    776\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m--> 777\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1199\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m   1196\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheckpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001B[39;00m\n\u001B[1;32m-> 1199\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001B[39;00m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_dispatch()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1279\u001B[0m, in \u001B[0;36mTrainer._dispatch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1277\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_type_plugin\u001B[38;5;241m.\u001B[39mstart_predicting(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1279\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_type_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_training\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:202\u001B[0m, in \u001B[0;36mTrainingTypePlugin.start_training\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mstart_training\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainer: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.Trainer\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# double dispatch to initiate the training loop\u001B[39;00m\n\u001B[1;32m--> 202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1289\u001B[0m, in \u001B[0;36mTrainer.run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m   1288\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[1;32m-> 1289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1319\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m   1318\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[1;32m-> 1319\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:145\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:234\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    231\u001B[0m data_fetcher \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mget_profiled_dataloader(dataloader)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;66;03m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001B[39;00m\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;66;03m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001B[39;00m\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;66;03m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;66;03m# TODO(@carmocca): deprecate and rename so users don't get confused\u001B[39;00m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:140\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_skip()\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m--> 140\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_run_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:141\u001B[0m, in \u001B[0;36mTrainingEpochLoop.on_run_start\u001B[1;34m(self, data_fetcher, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mepoch_progress\u001B[38;5;241m.\u001B[39mincrement_started()\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reload_dataloader_state_dict(data_fetcher)\n\u001B[1;32m--> 141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[43m_update_dataloader_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_idx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:121\u001B[0m, in \u001B[0;36m_update_dataloader_iter\u001B[1;34m(data_fetcher, batch_idx)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Attach the dataloader.\"\"\"\u001B[39;00m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# restore iteration\u001B[39;00m\n\u001B[1;32m--> 121\u001B[0m     dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    123\u001B[0m     dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(data_fetcher)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:198\u001B[0m, in \u001B[0;36mAbstractDataFetcher.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset()\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader)\n\u001B[1;32m--> 198\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_patch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprefetching(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprefetch_batches)\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:133\u001B[0m, in \u001B[0;36mAbstractDataFetcher._apply_patch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    130\u001B[0m         loader\u001B[38;5;241m.\u001B[39m_lightning_fetcher \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m    131\u001B[0m         patch_dataloader_iterator(loader, iterator, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 133\u001B[0m apply_to_collections(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaders, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader_iters\u001B[49m, (Iterator, DataLoader), _apply_patch_fn)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:181\u001B[0m, in \u001B[0;36mAbstractDataFetcher.loader_iters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `dataloader_iter` isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt available outside the __iter__ context.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader, CombinedLoader):\n\u001B[1;32m--> 181\u001B[0m     loader_iters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader_iter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader_iters\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    183\u001B[0m     loader_iters \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader_iter]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:537\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.loader_iters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the `_loader_iters` and create one if it is None.\"\"\"\u001B[39;00m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loader_iters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 537\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loader_iters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_loader_iters\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loader_iters\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:577\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.create_loader_iters\u001B[1;34m(loaders)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Create and return a collection of iterators from loaders.\u001B[39;00m\n\u001B[0;32m    569\u001B[0m \n\u001B[0;32m    570\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    574\u001B[0m \u001B[38;5;124;03m    a collections of iterators\u001B[39;00m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# dataloaders are Iterable but not Sequences. Need this to specifically exclude sequences\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_to_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwrong_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mSequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMapping\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:95\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[1;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;66;03m# Breaking condition\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype) \u001B[38;5;129;01mand\u001B[39;00m (wrong_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, wrong_dtype)):\n\u001B[1;32m---> 95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(data, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m elem_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(data)\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# Recursively apply to collection items\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:484\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    483\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 484\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    413\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 415\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1131\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1133\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1138\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\multiprocessing\\context.py:336\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot pickle 'module' object"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ðŸš€ Force PyTorch Lightning to use a single-process backend to avoid pickling issues\n",
    "os.environ[\"PL_TORCH_DISTRIBUTED_BACKEND\"] = \"gloo\"\n",
    "\n",
    "# Create the data module\n",
    "audioset_data = data_prep(full_dataset, config, device_num)\n",
    "\n",
    "# ðŸš€ Ensure `trainer` is removed before pickling\n",
    "if hasattr(audioset_data, \"trainer\"):\n",
    "    del audioset_data.trainer  # Remove the unpicklable object\n",
    "\n",
    "# ðŸ”¹ Set up the Trainer (without 'num_workers', which goes inside DataLoader)\n",
    "trainer = pl.Trainer(\n",
    "    deterministic=False,\n",
    "    default_root_dir=checkpoint_dir,\n",
    "    gpus=device_num,\n",
    "    val_check_interval=1.0,\n",
    "    max_epochs=config.max_epoch,\n",
    "    auto_lr_find=True,\n",
    "    sync_batchnorm=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    accelerator=\"ddp\" if device_num > 1 else None,\n",
    "    num_sanity_val_steps=0,\n",
    "    resume_from_checkpoint=None,\n",
    "    replace_sampler_ddp=False,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "\n",
    "# ðŸš€ Print before training to verify `trainer` is gone\n",
    "print(\"Before training, trainer in audioset_data:\", hasattr(audioset_data, \"trainer\"))\n",
    "\n",
    "# ðŸš€ Run training\n",
    "trainer.fit(model, audioset_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let us Check the Result\n",
    "\n",
    "Find the path of your saved checkpoint and paste it in the below variable.\n",
    "Then you are able to follow the below code for checking the prediction result of any sample you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:10:31.584338900Z",
     "start_time": "2025-03-31T10:10:31.584338900Z"
    }
   },
   "outputs": [],
   "source": [
    "# infer the single data to check the result\n",
    "# get a model you saved\n",
    "model_path = r\"C:\\Users\\Louis\\PycharmProjects\\HTS-AT(Conda)\\HTS-Audio-Transformer\\workspace\\results\\exp_htsat_esc_50\\checkpoint\\lightning_logs\\version_1\\checkpoints\\l-epoch=4-acc=0.815.ckpt\"\n",
    "\n",
    "# get the groundtruth\n",
    "meta = np.loadtxt(meta_path , delimiter=',', dtype='str', skiprows=1)\n",
    "gd = {}\n",
    "for label in meta:\n",
    "    name = label[0]\n",
    "    target = label[2]\n",
    "    gd[name] = target\n",
    "\n",
    "class Audio_Classification:\n",
    "    def __init__(self, model_path, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda')\n",
    "        self.sed_model = HTSAT_Swin_Transformer(\n",
    "            spec_size=config.htsat_spec_size,\n",
    "            patch_size=config.htsat_patch_size,\n",
    "            in_chans=1,\n",
    "            num_classes=config.classes_num,\n",
    "            window_size=config.htsat_window_size,\n",
    "            config = config,\n",
    "            depths = config.htsat_depth,\n",
    "            embed_dim = config.htsat_dim,\n",
    "            patch_stride=config.htsat_stride,\n",
    "            num_heads=config.htsat_num_head\n",
    "        )\n",
    "        ckpt = torch.load(model_path, map_location=\"cpu\")\n",
    "        temp_ckpt = {}\n",
    "        for key in ckpt[\"state_dict\"]:\n",
    "            temp_ckpt[key[10:]] = ckpt['state_dict'][key]\n",
    "        self.sed_model.load_state_dict(temp_ckpt)\n",
    "        self.sed_model.to(self.device)\n",
    "        self.sed_model.eval()\n",
    "\n",
    "\n",
    "    def predict(self, audiofile):\n",
    "\n",
    "        if audiofile:\n",
    "            waveform, sr = librosa.load(audiofile, sr=32000)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(waveform).float().to(self.device)\n",
    "                output_dict = self.sed_model(x[None, :], None, True)\n",
    "                pred = output_dict['clipwise_output']\n",
    "                pred_post = pred[0].detach().cpu().numpy()\n",
    "                pred_label = np.argmax(pred_post)\n",
    "                pred_prob = np.max(pred_post)\n",
    "            return pred_label, pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-31T10:10:31.589551900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "Audiocls = Audio_Classification(model_path, config)\n",
    "\n",
    "# pick any audio you like in the ESC-50 testing set (cross-validation)\n",
    "pred_label, pred_prob = Audiocls.predict(\"./workspace/esc-50/raw/ESC-50-master/audio/1-7456-A-13.wav\")\n",
    "\n",
    "print('Audiocls predict output: ', pred_label, pred_prob, gd[\"1-7456-A-13.wav\"])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-31T10:10:31.589551900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "htsat_env",
   "language": "python",
   "display_name": "Python (HTSAT_env)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb1a0df39641c41734bdd2d42699ec57167c4cf18fd061cdef52c16cce6262af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
