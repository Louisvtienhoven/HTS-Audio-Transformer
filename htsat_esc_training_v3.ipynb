{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on training a HTS-AT model for audio classification on the ESC-50 Dataset\n",
    "\n",
    "Referece: \n",
    "\n",
    "[HTS-AT: A Hierarchical Token-Semantic Audio Transformer for Sound Classification and Detection, ICASSP 2022](https://arxiv.org/abs/2202.00874)\n",
    "\n",
    "Following the HTS-AT's paper, in this tutorial, we would show how to use the HST-AT in the training of the ESC-50 Dataset.\n",
    "\n",
    "The [ESC-50 dataset](https://github.com/karolpiczak/ESC-50) is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification. The dataset consists of 5-second-long recordings organized into 50 semantical classes (with 40 examples per class) loosely arranged into 5 major categories\n",
    "\n",
    "Before running this tutorial, please make sure that you install the below packages by following steps:\n",
    "\n",
    "1. download [the codebase](https://github.com/RetroCirce/HTS-Audio-Transformer), and put this tutorial notebook inside the codebase folder.\n",
    "\n",
    "2. In the github code folder:\n",
    "\n",
    "    > pip install -r requirements.txt\n",
    "\n",
    "3. We do not include the installation of PyTorch in the requirment, since different machines require different vereions of CUDA and Toolkits. So make sure you install the PyTorch from [the official guidance](https://pytorch.org/).\n",
    "\n",
    "4. Install the 'SOX' and the 'ffmpeg', we recommend that you run this code in Linux inside the Conda environment. In that, you can install them by:\n",
    "\n",
    "    > sudo apt install sox\n",
    "    \n",
    "    > conda install -c conda-forge ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T11:16:42.025975900Z",
     "start_time": "2025-05-28T11:16:41.997994800Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:16:47.097326Z",
     "start_time": "2025-05-28T11:16:42.553996Z"
    }
   },
   "outputs": [],
   "source": [
    "# import basic packages\n",
    "import os\n",
    "import numpy as np\n",
    "import wget\n",
    "import sys\n",
    "import gdown\n",
    "import zipfile\n",
    "import librosa\n",
    "# in the notebook, we only can use one GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:16:47.108529300Z",
     "start_time": "2025-05-28T11:16:47.091674600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the workspace and download the needed files\n",
    "\n",
    "def create_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "workspace = \"./workspace\"\n",
    "dataset_path = os.path.join(workspace, \"esc-50\")\n",
    "checkpoint_path = os.path.join(workspace, \"ckpt\")\n",
    "esc_raw_path = os.path.join(dataset_path, 'raw')\n",
    "\n",
    "\n",
    "create_path(workspace)\n",
    "create_path(dataset_path)\n",
    "create_path(checkpoint_path)\n",
    "create_path(esc_raw_path)\n",
    "\n",
    "\n",
    "# download the esc-50 dataset\n",
    "\n",
    "if not os.path.exists(os.path.join(dataset_path, 'ESC-50-master.zip')):\n",
    "    print(\"-------------Downloading ESC-50 Dataset-------------\")\n",
    "    wget.download('https://github.com/karoldvl/ESC-50/archive/master.zip', out=dataset_path)\n",
    "    with zipfile.ZipFile(os.path.join(dataset_path, 'ESC-50-master.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall(esc_raw_path)\n",
    "    print(\"-------------Success-------------\")\n",
    "\n",
    "if not os.path.exists(os.path.join(checkpoint_path,'htsat_audioset_pretrain.ckpt')):\n",
    "    gdown.download(id='1OK8a5XuMVLyeVKF117L8pfxeZYdfSDZv', output=os.path.join(checkpoint_path,'htsat_audioset_pretrain.ckpt'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:16:48.159156100Z",
     "start_time": "2025-05-28T11:16:47.106349900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Resample ESC-50-------------\n",
      "-------------Success-------------\n",
      "-------------Build Dataset-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\numpy\\lib\\npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Success-------------\n"
     ]
    }
   ],
   "source": [
    "# Process ESC-50 Dataset\n",
    "meta_path = os.path.join(esc_raw_path, 'ESC-50-master', 'meta', 'meta_full.csv')\n",
    "audio_path = os.path.join(esc_raw_path, 'ESC-50-master', 'audio_full_v2')\n",
    "resample_path = os.path.join(dataset_path, 'resample')\n",
    "savedata_path = os.path.join(dataset_path, 'esc-50-data.npy')\n",
    "create_path(resample_path)\n",
    "\n",
    "meta = np.loadtxt(meta_path , delimiter=',', dtype='str', skiprows=1)\n",
    "audio_list = os.listdir(audio_path)\n",
    "\n",
    "# resample\n",
    "print(\"-------------Resample ESC-50-------------\")\n",
    "for f in audio_list:\n",
    "    full_f = os.path.join(audio_path, f)\n",
    "    resample_f = os.path.join(resample_path, f)\n",
    "    if not os.path.exists(resample_f):\n",
    "        os.system('sox -V1 ' + full_f + ' -r 32000 ' + resample_f)\n",
    "print(\"-------------Success-------------\")\n",
    "\n",
    "print(\"-------------Build Dataset-------------\")\n",
    "output_dict = [[] for _ in range(5)]\n",
    "for label in meta:\n",
    "    name = label[0]\n",
    "    fold = label[1]\n",
    "    target = label[2]\n",
    "    y, sr = librosa.load(os.path.join(resample_path, name), sr = None)\n",
    "    output_dict[int(fold) - 1].append(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"target\": int(target),\n",
    "            \"waveform\": y\n",
    "        }\n",
    "    )\n",
    "np.save(savedata_path, output_dict)\n",
    "print(\"-------------Success-------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:05.485515900Z",
     "start_time": "2025-05-28T11:16:48.148688200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model package\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "\n",
    "from utils import create_folder, dump_config, process_idc\n",
    "import esc_config as config\n",
    "from sed_model import SEDWrapper, Ensemble_SEDWrapper\n",
    "from data_generator import ESC_Dataset\n",
    "from model.htsat_in_chans_2 import HTSAT_Swin_Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:05.501811400Z",
     "start_time": "2025-05-28T11:17:05.491831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "class data_prep(pl.LightningDataModule):\n",
    "    def __init__(self, train_dataset, eval_dataset, device_num):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.device_num = device_num\n",
    "\n",
    "    # def train_dataloader(self):\n",
    "    #     train_sampler = DistributedSampler(self.train_dataset, shuffle = False) if self.device_num > 1 else None\n",
    "    #     train_loader = DataLoader(\n",
    "    #         dataset = self.train_dataset,\n",
    "    #         num_workers = 0, #config.num_workers,\n",
    "    #         batch_size = config.batch_size // self.device_num,\n",
    "    #         shuffle = False,\n",
    "    #         sampler = train_sampler\n",
    "    #     )\n",
    "    #     return train_loader\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # only use a sampler if you’re on >1 GPU\n",
    "        train_sampler = DistributedSampler(self.train_dataset, shuffle=False) if self.device_num > 1 else None\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset     = self.train_dataset,\n",
    "            num_workers = 0, #config.num_workers,     # e.g. 4–12\n",
    "            batch_size  = config.batch_size // self.device_num,\n",
    "            shuffle     = (train_sampler is None),# ← shuffle when not using DistributedSampler\n",
    "            sampler     = train_sampler\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        eval_sampler = DistributedSampler(self.eval_dataset, shuffle = False) if self.device_num > 1 else None\n",
    "        eval_loader = DataLoader(\n",
    "            dataset = self.eval_dataset,\n",
    "            num_workers = 0, #config.num_workers,\n",
    "            batch_size = config.batch_size // self.device_num,\n",
    "            shuffle = False,\n",
    "            sampler = eval_sampler\n",
    "        )\n",
    "        return eval_loader\n",
    "    def test_dataloader(self):\n",
    "        test_sampler = DistributedSampler(self.eval_dataset, shuffle = False) if self.device_num > 1 else None\n",
    "        test_loader = DataLoader(\n",
    "            dataset = self.eval_dataset,\n",
    "            num_workers = config.num_workers,\n",
    "            batch_size = config.batch_size // self.device_num,\n",
    "            shuffle = False,\n",
    "            sampler = test_sampler\n",
    "        )\n",
    "        return test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:05.647681100Z",
     "start_time": "2025-05-28T11:17:05.508661900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each batch size: 16\n",
      "Using ESC\n"
     ]
    }
   ],
   "source": [
    "# Set the workspace\n",
    "device_num = torch.cuda.device_count()\n",
    "print(\"each batch size:\", config.batch_size // device_num)\n",
    "\n",
    "full_dataset = np.load(os.path.join(config.dataset_path, \"esc-50-data.npy\"), allow_pickle = True)\n",
    "\n",
    "# set exp folder\n",
    "exp_dir = os.path.join(config.workspace, \"results\", config.exp_name)\n",
    "checkpoint_dir = os.path.join(config.workspace, \"results\", config.exp_name, \"checkpoint\")\n",
    "if not config.debug:\n",
    "    create_folder(os.path.join(config.workspace, \"results\"))\n",
    "    create_folder(exp_dir)\n",
    "    create_folder(checkpoint_dir)\n",
    "    dump_config(config, os.path.join(exp_dir, config.exp_name), False)\n",
    "\n",
    "print(\"Using ESC\")\n",
    "dataset = ESC_Dataset(\n",
    "    dataset = full_dataset,\n",
    "    config = config,\n",
    "    eval_mode = False\n",
    ")\n",
    "eval_dataset = ESC_Dataset(\n",
    "    dataset = full_dataset,\n",
    "    config = config,\n",
    "    eval_mode = True\n",
    ")\n",
    "\n",
    "audioset_data = data_prep(dataset, eval_dataset, device_num)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor = \"acc\",\n",
    "    filename='l-{epoch:d}-{acc:.3f}',\n",
    "    save_top_k = 20,\n",
    "    mode = \"max\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:06.371445400Z",
     "start_time": "2025-05-28T11:17:05.653391100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Set the Trainer\n",
    "trainer = pl.Trainer(\n",
    "    deterministic=False,\n",
    "    default_root_dir = checkpoint_dir,\n",
    "    gpus = device_num, \n",
    "    val_check_interval = 1.0,\n",
    "    max_epochs = config.max_epoch,\n",
    "    auto_lr_find = True,    \n",
    "    sync_batchnorm = True,\n",
    "    callbacks = [checkpoint_callback],\n",
    "    accelerator = \"ddp\" if device_num > 1 else None,\n",
    "    num_sanity_val_steps = 0,\n",
    "    resume_from_checkpoint = None, \n",
    "    replace_sampler_ddp = False,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "\n",
    "sed_model = HTSAT_Swin_Transformer(\n",
    "    pretrained=False,\n",
    "    spec_size=config.htsat_spec_size,\n",
    "    patch_size=config.htsat_patch_size,\n",
    "    in_chans=config.htsat_in_chans,\n",
    "    num_classes=config.classes_num,\n",
    "    window_size=config.htsat_window_size,\n",
    "    config = config,\n",
    "    depths = config.htsat_depth,\n",
    "    embed_dim = config.htsat_dim,\n",
    "    patch_stride=config.htsat_stride,\n",
    "    num_heads=config.htsat_num_head\n",
    ")\n",
    "\n",
    "model = SEDWrapper(\n",
    "    sed_model = sed_model, \n",
    "    config = config,\n",
    "    dataset = dataset\n",
    ")\n",
    "\n",
    "if config.resume_checkpoint is not None:\n",
    "    print(\"Load Checkpoint from \", config.resume_checkpoint)\n",
    "    ckpt = torch.load(config.resume_checkpoint, map_location=\"cpu\")\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.head.weight\")\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.head.bias\")\n",
    "    # finetune on the esc and spv2 dataset\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.tscam_conv.weight\")\n",
    "    ckpt[\"state_dict\"].pop(\"sed_model.tscam_conv.bias\")\n",
    "    model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T14:26:59.688446300Z",
     "start_time": "2025-05-28T13:38:44.344001700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | sed_model | HTSAT_Swin_Transformer | 28.6 M\n",
      "-----------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "1.1 M     Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.272   Total estimated model params size (MB)\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33da52e94789451aa5359d29a26b749c"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.009040355682373047,
       "ncols": null,
       "nrows": null,
       "prefix": "Training",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 24. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 31. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 34. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 44. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 41. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d8623e448504005a6f0151225810d26"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.011549949645996094,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.925}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e3424646f5943d1a820e639c908a1e6"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.0050470829010009766,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.9916666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 42. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba89ce1a2b6a42a8af7b89e756bf1295"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.007038116455078125,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.9833333333333333}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdd76659fabe490387a2bf381c95faab"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.007548093795776367,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.85}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a3875e4660f44daad352d25d3ed6357"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.0059850215911865234,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.8416666666666667}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed9a68b6981343d985b2f28bd0c73956"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.006036520004272461,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.9666666666666667}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77940dafb660472285522c629717d884"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.007977962493896484,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.9583333333333334}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01c0f479fecf4624a14cff7eee65c1f4"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.009000778198242188,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.975}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39e67423d53a4a7ba7fbeda1c75b9017"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.004988431930541992,
       "ncols": null,
       "nrows": null,
       "prefix": "Validating",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 {'acc': 0.975}\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Training the model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# You can set different fold index by setting 'esc_fold' to any number from 0-4 in esc_config.py\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maudioset_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#trainer.fit(model, datamodule=audioset_data)   \u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:740\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001B[0m\n\u001B[0;32m    735\u001B[0m     rank_zero_deprecation(\n\u001B[0;32m    736\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    737\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    738\u001B[0m     )\n\u001B[0;32m    739\u001B[0m     train_dataloaders \u001B[38;5;241m=\u001B[39m train_dataloader\n\u001B[1;32m--> 740\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    742\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:685\u001B[0m, in \u001B[0;36mTrainer._call_and_handle_interrupt\u001B[1;34m(self, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    676\u001B[0m \u001B[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;124;03mas all errors should funnel through them\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 685\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    686\u001B[0m \u001B[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001B[39;00m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:777\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;66;03m# TODO: ckpt_path only in v1.7\u001B[39;00m\n\u001B[0;32m    776\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m--> 777\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1199\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m   1196\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheckpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001B[39;00m\n\u001B[1;32m-> 1199\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001B[39;00m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_dispatch()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1279\u001B[0m, in \u001B[0;36mTrainer._dispatch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1277\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_type_plugin\u001B[38;5;241m.\u001B[39mstart_predicting(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1279\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_type_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_training\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:202\u001B[0m, in \u001B[0;36mTrainingTypePlugin.start_training\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mstart_training\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainer: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.Trainer\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# double dispatch to initiate the training loop\u001B[39;00m\n\u001B[1;32m--> 202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1289\u001B[0m, in \u001B[0;36mTrainer.run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m   1288\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[1;32m-> 1289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1319\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m   1318\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[1;32m-> 1319\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:145\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:234\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    231\u001B[0m data_fetcher \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mget_profiled_dataloader(dataloader)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;66;03m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001B[39;00m\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;66;03m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001B[39;00m\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;66;03m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;66;03m# TODO(@carmocca): deprecate and rename so users don't get confused\u001B[39;00m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:151\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    149\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_run_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:298\u001B[0m, in \u001B[0;36mTrainingEpochLoop.on_run_end\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mepoch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[0;32m    297\u001B[0m \u001B[38;5;66;03m# call train epoch end hooks\u001B[39;00m\n\u001B[1;32m--> 298\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mon_train_epoch_end\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mcall_hook(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_epoch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mlogger_connector\u001B[38;5;241m.\u001B[39mon_epoch_end()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1495\u001B[0m, in \u001B[0;36mTrainer.call_hook\u001B[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1493\u001B[0m callback_fx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, hook_name, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   1494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(callback_fx):\n\u001B[1;32m-> 1495\u001B[0m     callback_fx(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# next call hook in lightningModule\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\callback_hook.py:93\u001B[0m, in \u001B[0;36mTrainerCallbackHookMixin.on_train_epoch_end\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Called when the epoch ends.\"\"\"\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_epoch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:321\u001B[0m, in \u001B[0;36mModelCheckpoint.on_train_epoch_end\u001B[1;34m(self, trainer, pl_module)\u001B[0m\n\u001B[0;32m    314\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_skip_saving_checkpoint(trainer)\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_on_train_epoch_end\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_every_n_epochs \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (trainer\u001B[38;5;241m.\u001B[39mcurrent_epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_every_n_epochs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    320\u001B[0m ):\n\u001B[1;32m--> 321\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    322\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:396\u001B[0m, in \u001B[0;36mModelCheckpoint.save_checkpoint\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    391\u001B[0m monitor_candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_monitor_candidates(trainer, epoch\u001B[38;5;241m=\u001B[39mepoch, step\u001B[38;5;241m=\u001B[39mglobal_step)\n\u001B[0;32m    393\u001B[0m \u001B[38;5;66;03m# callback supports multiple simultaneous modes\u001B[39;00m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;66;03m# here we call each mode sequentially\u001B[39;00m\n\u001B[0;32m    395\u001B[0m \u001B[38;5;66;03m# Mode 1: save the top k checkpoints\u001B[39;00m\n\u001B[1;32m--> 396\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_top_k_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitor_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;66;03m# Mode 2: save monitor=None checkpoints\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:684\u001B[0m, in \u001B[0;36mModelCheckpoint._save_top_k_checkpoint\u001B[1;34m(self, trainer, monitor_candidates)\u001B[0m\n\u001B[0;32m    681\u001B[0m current \u001B[38;5;241m=\u001B[39m monitor_candidates\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmonitor)\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_monitor_top_k(trainer, current):\n\u001B[1;32m--> 684\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_best_and_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonitor_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[0;32m    686\u001B[0m     epoch \u001B[38;5;241m=\u001B[39m monitor_candidates\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:742\u001B[0m, in \u001B[0;36mModelCheckpoint._update_best_and_save\u001B[1;34m(self, current, trainer, monitor_candidates)\u001B[0m\n\u001B[0;32m    737\u001B[0m     step \u001B[38;5;241m=\u001B[39m monitor_candidates\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    738\u001B[0m     rank_zero_info(\n\u001B[0;32m    739\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124md\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, global step \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124md\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmonitor\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m reached \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m0.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    740\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (best \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_model_score\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m0.5f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m), saving model to \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m as top \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    741\u001B[0m     )\n\u001B[1;32m--> 742\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_weights_only\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m del_filepath \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filepath \u001B[38;5;241m!=\u001B[39m del_filepath:\n\u001B[0;32m    745\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtraining_type_plugin\u001B[38;5;241m.\u001B[39mremove_checkpoint(del_filepath)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1913\u001B[0m, in \u001B[0;36mTrainer.save_checkpoint\u001B[1;34m(self, filepath, weights_only)\u001B[0m\n\u001B[0;32m   1912\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msave_checkpoint\u001B[39m(\u001B[38;5;28mself\u001B[39m, filepath: _PATH, weights_only: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1913\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckpoint_connector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:472\u001B[0m, in \u001B[0;36mCheckpointConnector.save_checkpoint\u001B[1;34m(self, filepath, weights_only)\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m    filepath: write-target file's path\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;124;03m    weights_only: saving model weights only\u001B[39;00m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    471\u001B[0m _checkpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdump_checkpoint(weights_only)\n\u001B[1;32m--> 472\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_type_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_checkpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:294\u001B[0m, in \u001B[0;36mTrainingTypePlugin.save_checkpoint\u001B[1;34m(self, checkpoint, filepath)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \n\u001B[0;32m    289\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    checkpoint: dict containing model and trainer state\u001B[39;00m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m    filepath: write-target file's path\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshould_rank_save_checkpoint:\n\u001B[1;32m--> 294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckpoint_io\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\plugins\\io\\torch_plugin.py:37\u001B[0m, in \u001B[0;36mTorchCheckpointIO.save_checkpoint\u001B[1;34m(self, checkpoint, path, storage_options)\u001B[0m\n\u001B[0;32m     34\u001B[0m fs\u001B[38;5;241m.\u001B[39mmakedirs(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;66;03m# write the checkpoint dictionary on the file\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m     \u001B[43matomic_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;66;03m# todo (sean): is this try catch necessary still?\u001B[39;00m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# https://github.com/PyTorchLightning/pytorch-lightning/pull/431\u001B[39;00m\n\u001B[0;32m     41\u001B[0m     key \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mLightningModule\u001B[38;5;241m.\u001B[39mCHECKPOINT_HYPER_PARAMS_KEY\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py:70\u001B[0m, in \u001B[0;36matomic_save\u001B[1;34m(checkpoint, filepath)\u001B[0m\n\u001B[0;32m     68\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(checkpoint, bytesbuffer)\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m fsspec\u001B[38;5;241m.\u001B[39mopen(filepath, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m---> 70\u001B[0m     \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbytesbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\fsspec\\implementations\\local.py:432\u001B[0m, in \u001B[0;36mLocalFileOpener.write\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 432\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# You can set different fold index by setting 'esc_fold' to any number from 0-4 in esc_config.py\n",
    "trainer.fit(model, audioset_data)\n",
    "#trainer.fit(model, datamodule=audioset_data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let us Check the Result\n",
    "\n",
    "Find the path of your saved checkpoint and paste it in the below variable.\n",
    "Then you are able to follow the below code for checking the prediction result of any sample you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:06.418049300Z",
     "start_time": "2025-05-28T11:17:06.383205300Z"
    }
   },
   "outputs": [],
   "source": [
    "# infer the single data to check the result\n",
    "# get a model you saved\n",
    "model_path = r\"C:\\Users\\Louis\\PycharmProjects\\HTS-Audio-Transformer\\workspace\\results\\exp_htsat_esc_50\\checkpoint\\lightning_logs\\version_33\\checkpoints\\l-epoch=29-acc=0.992.ckpt\"\n",
    "\n",
    "# get the groundtruth\n",
    "meta = np.loadtxt(meta_path , delimiter=',', dtype='str', skiprows=1)\n",
    "gd = {}\n",
    "for label in meta:\n",
    "    name = label[0]\n",
    "    target = label[2]\n",
    "    gd[name] = target\n",
    "\n",
    "class Audio_Classification:\n",
    "    def __init__(self, model_path, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda')\n",
    "        self.sed_model = HTSAT_Swin_Transformer(\n",
    "            spec_size=config.htsat_spec_size,\n",
    "            patch_size=config.htsat_patch_size,\n",
    "            in_chans=config.htsat_in_chans,\n",
    "            num_classes=config.classes_num,\n",
    "            window_size=config.htsat_window_size,\n",
    "            config = config,\n",
    "            depths = config.htsat_depth,\n",
    "            embed_dim = config.htsat_dim,\n",
    "            patch_stride=config.htsat_stride,\n",
    "            num_heads=config.htsat_num_head\n",
    "        )\n",
    "        ckpt = torch.load(model_path, map_location=\"cpu\")\n",
    "        temp_ckpt = {}\n",
    "        for key in ckpt[\"state_dict\"]:\n",
    "            temp_ckpt[key[10:]] = ckpt['state_dict'][key]\n",
    "        self.sed_model.load_state_dict(temp_ckpt)\n",
    "        self.sed_model.to(self.device)\n",
    "        self.sed_model.eval()\n",
    "\n",
    "\n",
    "    def predict(self, audiofile):\n",
    "\n",
    "        if audiofile:\n",
    "            waveform, sr = librosa.load(audiofile, sr=32000)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x = torch.from_numpy(waveform).float().to(self.device)\n",
    "                output_dict = self.sed_model(x[None, :], None, True)\n",
    "                pred = output_dict['clipwise_output']\n",
    "                pred_post = pred[0].detach().cpu().numpy()\n",
    "                pred_label = np.argmax(pred_post)\n",
    "                pred_prob = np.max(pred_post)\n",
    "            return pred_label, pred_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T11:17:09.502386300Z",
     "start_time": "2025-05-28T11:17:06.409307900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_16804\\2147287213.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path, map_location=\"cpu\")\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Louis\\\\PycharmProjects\\\\HTS-Audio-Transformer\\\\workspace\\\\esc-50\\\\raw\\\\ESC-50-master\\\\audio_failure\\\\cycle_080.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLibsndfileError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\librosa\\core\\audio.py:149\u001B[0m, in \u001B[0;36mload\u001B[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 149\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSoundFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m sf_desc:\n\u001B[0;32m    150\u001B[0m         sr_native \u001B[38;5;241m=\u001B[39m sf_desc\u001B[38;5;241m.\u001B[39msamplerate\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\soundfile.py:690\u001B[0m, in \u001B[0;36mSoundFile.__init__\u001B[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info \u001B[38;5;241m=\u001B[39m _create_info_struct(file, mode, samplerate, channels,\n\u001B[0;32m    689\u001B[0m                                  \u001B[38;5;28mformat\u001B[39m, subtype, endian)\n\u001B[1;32m--> 690\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosefd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m(mode)\u001B[38;5;241m.\u001B[39missuperset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseekable():\n\u001B[0;32m    692\u001B[0m     \u001B[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\soundfile.py:1265\u001B[0m, in \u001B[0;36mSoundFile._open\u001B[1;34m(self, file, mode_int, closefd)\u001B[0m\n\u001B[0;32m   1264\u001B[0m     err \u001B[38;5;241m=\u001B[39m _snd\u001B[38;5;241m.\u001B[39msf_error(file_ptr)\n\u001B[1;32m-> 1265\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LibsndfileError(err, prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError opening \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname))\n\u001B[0;32m   1266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode_int \u001B[38;5;241m==\u001B[39m _snd\u001B[38;5;241m.\u001B[39mSFM_WRITE:\n\u001B[0;32m   1267\u001B[0m     \u001B[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001B[39;00m\n\u001B[0;32m   1268\u001B[0m     \u001B[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001B[39;00m\n\u001B[0;32m   1269\u001B[0m     \u001B[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001B[39;00m\n",
      "\u001B[1;31mLibsndfileError\u001B[0m: Error opening 'C:\\\\Users\\\\Louis\\\\PycharmProjects\\\\HTS-Audio-Transformer\\\\workspace\\\\esc-50\\\\raw\\\\ESC-50-master\\\\audio_failure\\\\cycle_080.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m Audiocls \u001B[38;5;241m=\u001B[39m Audio_Classification(model_path, config)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# pick any audio you like in the ESC-50 testing set (cross-validation)\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m pred_label, pred_prob \u001B[38;5;241m=\u001B[39m \u001B[43mAudiocls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mLouis\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mPycharmProjects\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mHTS-Audio-Transformer\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mworkspace\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mesc-50\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mraw\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mESC-50-master\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43maudio_failure\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mcycle_080.wav\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAudiocls predict output: \u001B[39m\u001B[38;5;124m'\u001B[39m, pred_label, pred_prob, gd[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcycle_080.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "Cell \u001B[1;32mIn[11], line 42\u001B[0m, in \u001B[0;36mAudio_Classification.predict\u001B[1;34m(self, audiofile)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, audiofile):\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m audiofile:\n\u001B[1;32m---> 42\u001B[0m         waveform, sr \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudiofile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     45\u001B[0m             x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(waveform)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\librosa\\core\\audio.py:166\u001B[0m, in \u001B[0;36mload\u001B[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, (\u001B[38;5;28mstr\u001B[39m, pathlib\u001B[38;5;241m.\u001B[39mPurePath)):\n\u001B[0;32m    165\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPySoundFile failed. Trying audioread instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 166\u001B[0m     y, sr_native \u001B[38;5;241m=\u001B[39m \u001B[43m__audioread_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m (exc)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\librosa\\core\\audio.py:190\u001B[0m, in \u001B[0;36m__audioread_load\u001B[1;34m(path, offset, duration, dtype)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load an audio buffer using audioread.\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \n\u001B[0;32m    186\u001B[0m \u001B[38;5;124;03mThis loads one block at a time, and then concatenates the results.\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    189\u001B[0m y \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 190\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43maudioread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m input_file:\n\u001B[0;32m    191\u001B[0m     sr_native \u001B[38;5;241m=\u001B[39m input_file\u001B[38;5;241m.\u001B[39msamplerate\n\u001B[0;32m    192\u001B[0m     n_channels \u001B[38;5;241m=\u001B[39m input_file\u001B[38;5;241m.\u001B[39mchannels\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\audioread\\__init__.py:127\u001B[0m, in \u001B[0;36maudio_open\u001B[1;34m(path, backends)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m BackendClass \u001B[38;5;129;01min\u001B[39;00m backends:\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 127\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBackendClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m DecodeError:\n\u001B[0;32m    129\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\HTSAT_env\\lib\\site-packages\\audioread\\rawread.py:59\u001B[0m, in \u001B[0;36mRawAudioFile.__init__\u001B[1;34m(self, filename)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fh \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m aifc\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fh)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Louis\\\\PycharmProjects\\\\HTS-Audio-Transformer\\\\workspace\\\\esc-50\\\\raw\\\\ESC-50-master\\\\audio_failure\\\\cycle_080.wav'"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "Audiocls = Audio_Classification(model_path, config)\n",
    "\n",
    "# pick any audio you like in the ESC-50 testing set (cross-validation)\n",
    "pred_label, pred_prob = Audiocls.predict(r\"C:\\Users\\Louis\\PycharmProjects\\HTS-Audio-Transformer\\workspace\\esc-50\\raw\\ESC-50-master\\audio_failure\\cycle_080.wav\")\n",
    "\n",
    "print('Audiocls predict output: ', pred_label, pred_prob, gd[\"cycle_080.wav\"])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_16804\\2147287213.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_p6_failure__cycle_004.wav => Predicted: 0, Prob: 5.8506, Ground Truth: 0\n",
      "cross_p6_failure__cycle_006.wav => Predicted: 0, Prob: 5.8653, Ground Truth: 0\n",
      "cross_p6_failure__cycle_008.wav => Predicted: 0, Prob: 9.5199, Ground Truth: 0\n",
      "cross_p6_failure__cycle_010.wav => Predicted: 0, Prob: 5.8615, Ground Truth: 0\n",
      "cross_p6_failure__cycle_012.wav => Predicted: 0, Prob: 5.6261, Ground Truth: 0\n",
      "cross_p6_failure__cycle_014.wav => Predicted: 0, Prob: 5.8699, Ground Truth: 0\n",
      "cross_p6_failure__cycle_016.wav => Predicted: 0, Prob: 5.9053, Ground Truth: 0\n",
      "cross_p6_failure__cycle_018.wav => Predicted: 0, Prob: 4.6203, Ground Truth: 0\n",
      "cross_p6_failure__cycle_020.wav => Predicted: 0, Prob: 5.8579, Ground Truth: 0\n",
      "cross_p6_failure__cycle_022.wav => Predicted: 0, Prob: 5.8584, Ground Truth: 0\n",
      "cross_p6_failure__cycle_024.wav => Predicted: 0, Prob: 5.9337, Ground Truth: 0\n",
      "cross_p6_failure__cycle_026.wav => Predicted: 0, Prob: 4.6209, Ground Truth: 0\n",
      "cross_p6_failure__cycle_028.wav => Predicted: 0, Prob: 5.8617, Ground Truth: 0\n",
      "cross_p6_failure__cycle_030.wav => Predicted: 0, Prob: 5.8692, Ground Truth: 0\n",
      "cross_p6_failure__cycle_032.wav => Predicted: 0, Prob: 10.5045, Ground Truth: 0\n",
      "cross_p6_failure__cycle_039.wav => Predicted: 0, Prob: 5.9540, Ground Truth: 0\n",
      "cross_p6_failure__cycle_041.wav => Predicted: 0, Prob: 5.9073, Ground Truth: 0\n",
      "cross_p6_failure__cycle_043.wav => Predicted: 0, Prob: 4.6296, Ground Truth: 0\n",
      "cross_p6_failure__cycle_045.wav => Predicted: 0, Prob: 5.8774, Ground Truth: 0\n",
      "cross_p6_failure__cycle_047.wav => Predicted: 0, Prob: 5.3937, Ground Truth: 0\n",
      "cross_p6_failure__cycle_049.wav => Predicted: 0, Prob: 4.3316, Ground Truth: 0\n",
      "cross_p6_failure__cycle_051.wav => Predicted: 0, Prob: 5.1543, Ground Truth: 0\n",
      "cross_p6_failure__cycle_053.wav => Predicted: 0, Prob: 4.6105, Ground Truth: 0\n",
      "cross_p6_failure__cycle_055.wav => Predicted: 0, Prob: 2.7114, Ground Truth: 0\n",
      "cross_p6_failure__cycle_057.wav => Predicted: 0, Prob: 5.9115, Ground Truth: 0\n",
      "cross_p6_failure__cycle_059.wav => Predicted: 0, Prob: 5.3811, Ground Truth: 0\n",
      "cross_p6_failure__cycle_061.wav => Predicted: 0, Prob: 6.0172, Ground Truth: 0\n",
      "cross_p6_failure__cycle_063.wav => Predicted: 0, Prob: 6.0158, Ground Truth: 0\n",
      "cross_p6_failure__cycle_065.wav => Predicted: 0, Prob: 5.8839, Ground Truth: 0\n",
      "cross_p6_failure__cycle_067.wav => Predicted: 0, Prob: 6.0450, Ground Truth: 0\n",
      "cross_p6_failure__cycle_069.wav => Predicted: 0, Prob: 5.8618, Ground Truth: 0\n",
      "cross_p6_failure__cycle_071.wav => Predicted: 0, Prob: 5.3190, Ground Truth: 0\n",
      "cross_p6_failure__cycle_073.wav => Predicted: 0, Prob: 4.6171, Ground Truth: 0\n",
      "cross_p6_failure__cycle_075.wav => Predicted: 0, Prob: 5.2134, Ground Truth: 0\n",
      "cross_p6_failure__cycle_077.wav => Predicted: 0, Prob: 7.5303, Ground Truth: 0\n",
      "cross_p6_failure__cycle_079.wav => Predicted: 0, Prob: 5.3215, Ground Truth: 0\n",
      "cross_p6_failure__cycle_081.wav => Predicted: 0, Prob: 4.6267, Ground Truth: 0\n",
      "cross_p6_failure__cycle_083.wav => Predicted: 0, Prob: 6.2193, Ground Truth: 0\n",
      "cross_p6_failure__cycle_085.wav => Predicted: 0, Prob: 4.6713, Ground Truth: 0\n",
      "cross_p6_failure__cycle_087.wav => Predicted: 0, Prob: 4.5888, Ground Truth: 0\n",
      "cross_p6_failure__cycle_089.wav => Predicted: 0, Prob: 4.6175, Ground Truth: 0\n",
      "cross_p6_failure__cycle_091.wav => Predicted: 0, Prob: 4.5996, Ground Truth: 0\n",
      "cross_p6_failure__cycle_093.wav => Predicted: 0, Prob: 5.8677, Ground Truth: 0\n",
      "cross_p6_failure__cycle_095.wav => Predicted: 0, Prob: 6.0751, Ground Truth: 0\n",
      "cross_p6_failure__cycle_097.wav => Predicted: 0, Prob: 4.5783, Ground Truth: 0\n",
      "cross_p6_failure__cycle_099.wav => Predicted: 0, Prob: 5.8528, Ground Truth: 0\n",
      "cross_p6_failure__cycle_101.wav => Predicted: 0, Prob: 2.9525, Ground Truth: 0\n",
      "cross_p6_failure__cycle_103_noise0.wav => Predicted: 1, Prob: 4.6390, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise1.wav => Predicted: 1, Prob: 4.6392, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise10.wav => Predicted: 1, Prob: 4.6338, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise11.wav => Predicted: 1, Prob: 4.6375, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise12.wav => Predicted: 1, Prob: 4.6271, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise13.wav => Predicted: 1, Prob: 4.6359, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise14.wav => Predicted: 1, Prob: 4.6440, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise15.wav => Predicted: 1, Prob: 4.6434, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise16.wav => Predicted: 1, Prob: 4.6482, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise17.wav => Predicted: 1, Prob: 4.6343, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise18.wav => Predicted: 1, Prob: 4.6352, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise19.wav => Predicted: 1, Prob: 2.1957, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise2.wav => Predicted: 1, Prob: 4.6387, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise20.wav => Predicted: 1, Prob: 4.6380, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise21.wav => Predicted: 1, Prob: 4.6457, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise22.wav => Predicted: 1, Prob: 5.1963, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise23.wav => Predicted: 1, Prob: 4.6479, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise24.wav => Predicted: 1, Prob: 4.6465, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise25.wav => Predicted: 1, Prob: 4.6302, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise26.wav => Predicted: 1, Prob: 4.6138, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise27.wav => Predicted: 1, Prob: 4.6406, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise28.wav => Predicted: 1, Prob: 4.6583, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise29.wav => Predicted: 1, Prob: 4.6432, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise3.wav => Predicted: 1, Prob: 4.6389, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise4.wav => Predicted: 1, Prob: 4.6386, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise5.wav => Predicted: 1, Prob: 4.6370, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise6.wav => Predicted: 1, Prob: 4.6395, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise7.wav => Predicted: 1, Prob: 4.6404, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise8.wav => Predicted: 1, Prob: 4.6399, Ground Truth: 1\n",
      "cross_p6_failure__cycle_103_noise9.wav => Predicted: 1, Prob: 4.6389, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise0.wav => Predicted: 1, Prob: 4.6548, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise1.wav => Predicted: 1, Prob: 4.6543, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise10.wav => Predicted: 1, Prob: 4.6418, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise11.wav => Predicted: 1, Prob: 4.6334, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise12.wav => Predicted: 1, Prob: 4.6639, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise13.wav => Predicted: 1, Prob: 4.6417, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise14.wav => Predicted: 1, Prob: 4.6809, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise15.wav => Predicted: 1, Prob: 4.6401, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise16.wav => Predicted: 1, Prob: 4.6465, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise17.wav => Predicted: 1, Prob: 4.6412, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise18.wav => Predicted: 1, Prob: 4.6466, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise19.wav => Predicted: 1, Prob: 4.6433, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise2.wav => Predicted: 1, Prob: 4.6546, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise20.wav => Predicted: 1, Prob: 4.6582, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise21.wav => Predicted: 1, Prob: 4.6852, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise22.wav => Predicted: 1, Prob: 4.6533, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise23.wav => Predicted: 1, Prob: 4.6443, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise24.wav => Predicted: 1, Prob: 4.6823, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise25.wav => Predicted: 1, Prob: 4.6501, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise26.wav => Predicted: 1, Prob: 5.2065, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise27.wav => Predicted: 1, Prob: 4.6429, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise28.wav => Predicted: 1, Prob: 5.1568, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise29.wav => Predicted: 1, Prob: 4.7215, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise3.wav => Predicted: 1, Prob: 4.6432, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise4.wav => Predicted: 1, Prob: 4.6567, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise5.wav => Predicted: 1, Prob: 4.6492, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise6.wav => Predicted: 1, Prob: 4.6433, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise7.wav => Predicted: 1, Prob: 4.6417, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise8.wav => Predicted: 1, Prob: 4.6325, Ground Truth: 1\n",
      "cross_p6_failure__cycle_105_noise9.wav => Predicted: 1, Prob: 4.6491, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise0.wav => Predicted: 1, Prob: 4.6425, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise1.wav => Predicted: 1, Prob: 4.6425, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise10.wav => Predicted: 1, Prob: 4.6441, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise11.wav => Predicted: 1, Prob: 4.6422, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise12.wav => Predicted: 1, Prob: 4.6438, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise13.wav => Predicted: 1, Prob: 4.6436, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise14.wav => Predicted: 1, Prob: 4.6435, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise15.wav => Predicted: 1, Prob: 4.6442, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise16.wav => Predicted: 1, Prob: 4.6425, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise17.wav => Predicted: 1, Prob: 4.6429, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise18.wav => Predicted: 1, Prob: 4.6227, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise19.wav => Predicted: 1, Prob: 4.6428, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise2.wav => Predicted: 1, Prob: 4.6424, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise20.wav => Predicted: 1, Prob: 4.6491, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise21.wav => Predicted: 1, Prob: 4.6444, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise22.wav => Predicted: 1, Prob: 4.6431, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise23.wav => Predicted: 1, Prob: 4.6397, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise24.wav => Predicted: 1, Prob: 4.5604, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise25.wav => Predicted: 1, Prob: 4.6513, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise26.wav => Predicted: 1, Prob: 4.6808, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise27.wav => Predicted: 1, Prob: 4.6642, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise28.wav => Predicted: 1, Prob: 4.6556, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise29.wav => Predicted: 1, Prob: 4.6350, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise3.wav => Predicted: 1, Prob: 4.6419, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise4.wav => Predicted: 1, Prob: 4.6430, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise5.wav => Predicted: 1, Prob: 4.6426, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise6.wav => Predicted: 1, Prob: 4.6419, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise7.wav => Predicted: 1, Prob: 4.6579, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise8.wav => Predicted: 1, Prob: 4.6421, Ground Truth: 1\n",
      "cross_p6_failure__cycle_107_noise9.wav => Predicted: 1, Prob: 4.6435, Ground Truth: 1\n",
      "cross_p7s1_cycle_004.wav => Predicted: 0, Prob: 1.6148, Ground Truth: 0\n",
      "cross_p7s1_cycle_006.wav => Predicted: 0, Prob: 3.0756, Ground Truth: 0\n",
      "cross_p7s1_cycle_008.wav => Predicted: 0, Prob: 4.6037, Ground Truth: 0\n",
      "cross_p7s1_cycle_010.wav => Predicted: 0, Prob: 4.6051, Ground Truth: 0\n",
      "cross_p7s1_cycle_012.wav => Predicted: 0, Prob: 4.6071, Ground Truth: 0\n",
      "cross_p7s1_cycle_014.wav => Predicted: 0, Prob: 4.6032, Ground Truth: 0\n",
      "cross_p7s1_cycle_016.wav => Predicted: 0, Prob: 4.6151, Ground Truth: 0\n",
      "cross_p7s1_cycle_018.wav => Predicted: 0, Prob: 4.5859, Ground Truth: 0\n",
      "cross_p7s1_cycle_020.wav => Predicted: 0, Prob: 4.6057, Ground Truth: 0\n",
      "cross_p7s1_cycle_022.wav => Predicted: 0, Prob: 4.6056, Ground Truth: 0\n",
      "cross_p7s1_cycle_024.wav => Predicted: 0, Prob: 4.6077, Ground Truth: 0\n",
      "cross_p7s1_cycle_026.wav => Predicted: 0, Prob: 4.6006, Ground Truth: 0\n",
      "cross_p7s1_cycle_028.wav => Predicted: 0, Prob: 4.6059, Ground Truth: 0\n",
      "cross_p7s1_cycle_030.wav => Predicted: 0, Prob: 5.8525, Ground Truth: 0\n",
      "cross_p7s1_cycle_032.wav => Predicted: 0, Prob: 4.6025, Ground Truth: 0\n",
      "cross_p7s1_cycle_034.wav => Predicted: 0, Prob: 4.5789, Ground Truth: 0\n",
      "cross_p7s1_cycle_036.wav => Predicted: 0, Prob: 4.4818, Ground Truth: 0\n",
      "cross_p7s1_cycle_038.wav => Predicted: 0, Prob: 4.3891, Ground Truth: 0\n",
      "cross_p7s1_cycle_040.wav => Predicted: 0, Prob: 4.6052, Ground Truth: 0\n",
      "cross_p7s1_cycle_042.wav => Predicted: 0, Prob: 5.8729, Ground Truth: 0\n",
      "cross_p7s1_cycle_044.wav => Predicted: 0, Prob: 5.8481, Ground Truth: 0\n",
      "cross_p7s1_cycle_046.wav => Predicted: 0, Prob: 3.0491, Ground Truth: 0\n",
      "cross_p7s1_cycle_048.wav => Predicted: 0, Prob: 5.8674, Ground Truth: 0\n",
      "cross_p7s1_cycle_054.wav => Predicted: 0, Prob: 4.5953, Ground Truth: 0\n",
      "cross_p7s1_cycle_056.wav => Predicted: 0, Prob: 3.0700, Ground Truth: 0\n",
      "cross_p7s1_cycle_058.wav => Predicted: 0, Prob: 5.3245, Ground Truth: 0\n",
      "cross_p7s1_cycle_062.wav => Predicted: 0, Prob: 4.1764, Ground Truth: 0\n",
      "cross_p7s1_cycle_064.wav => Predicted: 0, Prob: 4.5816, Ground Truth: 0\n",
      "cross_p7s1_cycle_066.wav => Predicted: 1, Prob: 4.6441, Ground Truth: 0\n",
      "cross_p7s1_cycle_068.wav => Predicted: 0, Prob: 5.3640, Ground Truth: 0\n",
      "cross_p7s1_cycle_070.wav => Predicted: 0, Prob: 5.8715, Ground Truth: 0\n",
      "cross_p7s1_cycle_072.wav => Predicted: 0, Prob: 5.8637, Ground Truth: 0\n",
      "cross_p7s1_cycle_074.wav => Predicted: 0, Prob: 4.5936, Ground Truth: 0\n",
      "cross_p7s1_cycle_076.wav => Predicted: 0, Prob: 5.8662, Ground Truth: 0\n",
      "cross_p7s1_cycle_078.wav => Predicted: 0, Prob: 5.8441, Ground Truth: 0\n",
      "cross_p7s1_cycle_080.wav => Predicted: 0, Prob: 4.5588, Ground Truth: 0\n",
      "cross_p7s1_cycle_082.wav => Predicted: 0, Prob: 5.3701, Ground Truth: 0\n",
      "cross_p7s1_cycle_084.wav => Predicted: 0, Prob: 5.8689, Ground Truth: 0\n",
      "cross_p7s1_cycle_086.wav => Predicted: 0, Prob: 5.8662, Ground Truth: 0\n",
      "cross_p7s1_cycle_088.wav => Predicted: 0, Prob: 5.3676, Ground Truth: 0\n",
      "cross_p7s1_cycle_090.wav => Predicted: 0, Prob: 4.5845, Ground Truth: 0\n",
      "cross_p7s1_cycle_092.wav => Predicted: 0, Prob: 5.8749, Ground Truth: 0\n",
      "cross_p7s1_cycle_094.wav => Predicted: 0, Prob: 2.3978, Ground Truth: 0\n",
      "cross_p7s1_cycle_096.wav => Predicted: 0, Prob: 4.5871, Ground Truth: 0\n",
      "cross_p7s1_cycle_098.wav => Predicted: 0, Prob: 5.8704, Ground Truth: 0\n",
      "cross_p7s1_cycle_100.wav => Predicted: 0, Prob: 4.5710, Ground Truth: 0\n",
      "cross_p7s1_cycle_102.wav => Predicted: 0, Prob: 5.8717, Ground Truth: 0\n",
      "cross_p7s1_cycle_104.wav => Predicted: 0, Prob: 4.6065, Ground Truth: 0\n",
      "cross_p7s1_cycle_106.wav => Predicted: 0, Prob: 5.3705, Ground Truth: 0\n",
      "cross_p7s1_cycle_112.wav => Predicted: 0, Prob: 4.6139, Ground Truth: 0\n",
      "cross_p7s1_cycle_114.wav => Predicted: 0, Prob: 4.5761, Ground Truth: 0\n",
      "cross_p7s1_cycle_116.wav => Predicted: 0, Prob: 3.1448, Ground Truth: 0\n",
      "cross_p7s1_cycle_118.wav => Predicted: 0, Prob: 4.6109, Ground Truth: 0\n",
      "cross_p7s1_cycle_120.wav => Predicted: 0, Prob: 4.5980, Ground Truth: 0\n",
      "cross_p7s1_cycle_122.wav => Predicted: 0, Prob: 4.5979, Ground Truth: 0\n",
      "cross_p7s1_cycle_124.wav => Predicted: 0, Prob: 4.6210, Ground Truth: 0\n",
      "cross_p7s1_cycle_126.wav => Predicted: 0, Prob: 4.6171, Ground Truth: 0\n",
      "cross_p7s1_cycle_128.wav => Predicted: 0, Prob: 4.6134, Ground Truth: 0\n",
      "cross_p7s1_cycle_130.wav => Predicted: 0, Prob: 4.5988, Ground Truth: 0\n",
      "cross_p7s1_cycle_132.wav => Predicted: 0, Prob: 4.5970, Ground Truth: 0\n",
      "cross_p7s1_cycle_134.wav => Predicted: 0, Prob: 4.6114, Ground Truth: 0\n",
      "cross_p7s1_cycle_136.wav => Predicted: 0, Prob: 4.6164, Ground Truth: 0\n",
      "cross_p7s1_cycle_138.wav => Predicted: 0, Prob: 5.9132, Ground Truth: 0\n",
      "cross_p7s1_cycle_142.wav => Predicted: 0, Prob: 4.5866, Ground Truth: 0\n",
      "cross_p7s1_cycle_144.wav => Predicted: 0, Prob: 4.6111, Ground Truth: 0\n",
      "cross_p7s1_cycle_146.wav => Predicted: 0, Prob: 4.5963, Ground Truth: 0\n",
      "cross_p7s1_cycle_148.wav => Predicted: 0, Prob: 4.5971, Ground Truth: 0\n",
      "cross_p7s1_cycle_150.wav => Predicted: 0, Prob: 4.6070, Ground Truth: 0\n",
      "cross_p7s1_cycle_152.wav => Predicted: 0, Prob: 4.6151, Ground Truth: 0\n",
      "cross_p7s1_cycle_154.wav => Predicted: 0, Prob: 4.6117, Ground Truth: 0\n",
      "cross_p7s1_cycle_156.wav => Predicted: 0, Prob: 5.8830, Ground Truth: 0\n",
      "cross_p7s1_cycle_158.wav => Predicted: 0, Prob: 4.6135, Ground Truth: 0\n",
      "cross_p7s1_cycle_160.wav => Predicted: 0, Prob: 4.6158, Ground Truth: 0\n",
      "cross_p7s1_cycle_162.wav => Predicted: 0, Prob: 5.9025, Ground Truth: 0\n",
      "cross_p7s1_cycle_164.wav => Predicted: 0, Prob: 4.6158, Ground Truth: 0\n",
      "cross_p7s1_cycle_166.wav => Predicted: 0, Prob: 4.5986, Ground Truth: 0\n",
      "cross_p7s1_cycle_168.wav => Predicted: 0, Prob: 4.6054, Ground Truth: 0\n",
      "cross_p7s1_cycle_170.wav => Predicted: 0, Prob: 4.6162, Ground Truth: 0\n",
      "cross_p7s1_cycle_172.wav => Predicted: 0, Prob: 4.6174, Ground Truth: 0\n",
      "cross_p7s1_cycle_174.wav => Predicted: 0, Prob: 4.6108, Ground Truth: 0\n",
      "cross_p7s1_cycle_176.wav => Predicted: 0, Prob: 3.1325, Ground Truth: 0\n",
      "cross_p7s1_cycle_178.wav => Predicted: 0, Prob: 4.6154, Ground Truth: 0\n",
      "cross_p7s1_cycle_180.wav => Predicted: 0, Prob: 4.6143, Ground Truth: 0\n",
      "cross_p7s1_cycle_182.wav => Predicted: 0, Prob: 4.6173, Ground Truth: 0\n",
      "cross_p7s1_cycle_184.wav => Predicted: 0, Prob: 4.5942, Ground Truth: 0\n",
      "cross_p7s1_cycle_186.wav => Predicted: 0, Prob: 4.6153, Ground Truth: 0\n",
      "cross_p7s1_cycle_192.wav => Predicted: 0, Prob: 4.5469, Ground Truth: 0\n",
      "cross_p7s1_cycle_194.wav => Predicted: 0, Prob: 5.3709, Ground Truth: 0\n",
      "cross_p7s1_cycle_196.wav => Predicted: 0, Prob: 4.6091, Ground Truth: 0\n",
      "cross_p7s1_cycle_198.wav => Predicted: 0, Prob: 2.4164, Ground Truth: 0\n",
      "cross_p7s1_cycle_200.wav => Predicted: 0, Prob: 4.5289, Ground Truth: 0\n",
      "cross_p7s1_cycle_202.wav => Predicted: 0, Prob: 5.8520, Ground Truth: 0\n",
      "cross_p7s1_cycle_204.wav => Predicted: 0, Prob: 5.5194, Ground Truth: 0\n",
      "cross_p7s1_cycle_206.wav => Predicted: 0, Prob: 5.3426, Ground Truth: 0\n",
      "cross_p7s1_cycle_208.wav => Predicted: 0, Prob: 4.5977, Ground Truth: 0\n",
      "cross_p7s1_cycle_210.wav => Predicted: 0, Prob: 2.4059, Ground Truth: 0\n",
      "cross_p7s1_cycle_212.wav => Predicted: 0, Prob: 2.3996, Ground Truth: 0\n",
      "cross_p7s1_cycle_214.wav => Predicted: 0, Prob: 4.5780, Ground Truth: 0\n",
      "cross_p7s1_cycle_216.wav => Predicted: 0, Prob: 5.3739, Ground Truth: 0\n",
      "cross_p7s1_cycle_218.wav => Predicted: 0, Prob: 5.8662, Ground Truth: 0\n",
      "cross_p7s1_cycle_220.wav => Predicted: 0, Prob: 4.5848, Ground Truth: 0\n",
      "cross_p7s1_cycle_227.wav => Predicted: 0, Prob: 1.6166, Ground Truth: 0\n",
      "cross_p7s1_cycle_229.wav => Predicted: 0, Prob: 4.6160, Ground Truth: 0\n",
      "cross_p7s1_cycle_231.wav => Predicted: 0, Prob: 4.5867, Ground Truth: 0\n",
      "cross_p7s1_cycle_233.wav => Predicted: 0, Prob: 4.6033, Ground Truth: 0\n",
      "cross_p7s1_cycle_235.wav => Predicted: 0, Prob: 4.6091, Ground Truth: 0\n",
      "cross_p7s1_cycle_237.wav => Predicted: 0, Prob: 4.6128, Ground Truth: 0\n",
      "cross_p7s1_cycle_239.wav => Predicted: 0, Prob: 4.6144, Ground Truth: 0\n",
      "cross_p7s1_cycle_241.wav => Predicted: 0, Prob: 4.6103, Ground Truth: 0\n",
      "cross_p7s1_cycle_243.wav => Predicted: 0, Prob: 5.8523, Ground Truth: 0\n",
      "cross_p7s1_cycle_245.wav => Predicted: 0, Prob: 5.8421, Ground Truth: 0\n",
      "cross_p7s1_cycle_247.wav => Predicted: 0, Prob: 4.6120, Ground Truth: 0\n",
      "cross_p7s1_cycle_249.wav => Predicted: 0, Prob: 4.6042, Ground Truth: 0\n",
      "cross_p7s1_cycle_251.wav => Predicted: 0, Prob: 4.6142, Ground Truth: 0\n",
      "cross_p7s1_cycle_253.wav => Predicted: 0, Prob: 4.6053, Ground Truth: 0\n",
      "cross_p7s1_cycle_255.wav => Predicted: 0, Prob: 4.6131, Ground Truth: 0\n",
      "cross_p7s1_cycle_257.wav => Predicted: 0, Prob: 4.6119, Ground Truth: 0\n",
      "cross_p7s1_cycle_259.wav => Predicted: 0, Prob: 4.6055, Ground Truth: 0\n",
      "cross_p7s1_cycle_261.wav => Predicted: 0, Prob: 4.6082, Ground Truth: 0\n",
      "cross_p7s1_cycle_263.wav => Predicted: 0, Prob: 4.6128, Ground Truth: 0\n",
      "cross_p7s1_cycle_267.wav => Predicted: 0, Prob: 4.6118, Ground Truth: 0\n",
      "cross_p7s1_cycle_269.wav => Predicted: 0, Prob: 4.6131, Ground Truth: 0\n",
      "cross_p7s1_cycle_271.wav => Predicted: 0, Prob: 4.6121, Ground Truth: 0\n",
      "cross_p7s1_cycle_273.wav => Predicted: 0, Prob: 4.6148, Ground Truth: 0\n",
      "cross_p7s1_cycle_275.wav => Predicted: 0, Prob: 5.8548, Ground Truth: 0\n",
      "cross_p7s1_cycle_277.wav => Predicted: 0, Prob: 5.8637, Ground Truth: 0\n",
      "cross_p7s1_cycle_279.wav => Predicted: 0, Prob: 4.6091, Ground Truth: 0\n",
      "cross_p7s1_cycle_281.wav => Predicted: 0, Prob: 4.6094, Ground Truth: 0\n",
      "cross_p7s1_cycle_283.wav => Predicted: 0, Prob: 4.6055, Ground Truth: 0\n",
      "cross_p7s1_cycle_285.wav => Predicted: 0, Prob: 4.6007, Ground Truth: 0\n",
      "cross_p7s1_cycle_287.wav => Predicted: 0, Prob: 4.6148, Ground Truth: 0\n",
      "cross_p7s1_cycle_289.wav => Predicted: 0, Prob: 4.6123, Ground Truth: 0\n",
      "cross_p7s1_cycle_291.wav => Predicted: 0, Prob: 4.6005, Ground Truth: 0\n",
      "cross_p7s1_cycle_293.wav => Predicted: 0, Prob: 4.6115, Ground Truth: 0\n",
      "cross_p7s1_cycle_295.wav => Predicted: 0, Prob: 4.5665, Ground Truth: 0\n",
      "cross_p7s1_cycle_297.wav => Predicted: 0, Prob: 4.6147, Ground Truth: 0\n",
      "cross_p7s1_cycle_299.wav => Predicted: 0, Prob: 4.5914, Ground Truth: 0\n",
      "cross_p7s1_cycle_301.wav => Predicted: 0, Prob: 4.6112, Ground Truth: 0\n",
      "cross_p7s1_cycle_303.wav => Predicted: 0, Prob: 4.6103, Ground Truth: 0\n",
      "cross_p7s1_cycle_307.wav => Predicted: 0, Prob: 4.6131, Ground Truth: 0\n",
      "cross_p7s1_cycle_309.wav => Predicted: 0, Prob: 4.6074, Ground Truth: 0\n",
      "cross_p7s1_cycle_311.wav => Predicted: 0, Prob: 4.6070, Ground Truth: 0\n",
      "cross_p7s1_cycle_313.wav => Predicted: 0, Prob: 4.6179, Ground Truth: 0\n",
      "cross_p7s1_cycle_315.wav => Predicted: 0, Prob: 4.6137, Ground Truth: 0\n",
      "cross_p7s1_cycle_317.wav => Predicted: 0, Prob: 4.6130, Ground Truth: 0\n",
      "cross_p7s1_cycle_319.wav => Predicted: 0, Prob: 4.6022, Ground Truth: 0\n",
      "cross_p7s1_cycle_321.wav => Predicted: 0, Prob: 4.6123, Ground Truth: 0\n",
      "cross_p7s1_cycle_323.wav => Predicted: 0, Prob: 4.6139, Ground Truth: 0\n",
      "cross_p7s1_cycle_325.wav => Predicted: 0, Prob: 4.6098, Ground Truth: 0\n",
      "cross_p7s1_cycle_327.wav => Predicted: 0, Prob: 4.6165, Ground Truth: 0\n",
      "cross_p7s1_cycle_329.wav => Predicted: 0, Prob: 4.6123, Ground Truth: 0\n",
      "cross_p7s1_cycle_331.wav => Predicted: 0, Prob: 4.6144, Ground Truth: 0\n",
      "cross_p7s1_cycle_333.wav => Predicted: 0, Prob: 4.6143, Ground Truth: 0\n",
      "cross_p7s1_cycle_335.wav => Predicted: 0, Prob: 4.6106, Ground Truth: 0\n",
      "cross_p7s1_cycle_339.wav => Predicted: 0, Prob: 4.6146, Ground Truth: 0\n",
      "cross_p7s1_cycle_341.wav => Predicted: 0, Prob: 4.5974, Ground Truth: 0\n",
      "cross_p7s1_cycle_343.wav => Predicted: 0, Prob: 4.5967, Ground Truth: 0\n",
      "cross_p7s1_cycle_345.wav => Predicted: 0, Prob: 4.5985, Ground Truth: 0\n",
      "cross_p7s1_cycle_347.wav => Predicted: 0, Prob: 4.5960, Ground Truth: 0\n",
      "cross_p7s1_cycle_349.wav => Predicted: 0, Prob: 4.6138, Ground Truth: 0\n",
      "cross_p7s1_cycle_351.wav => Predicted: 0, Prob: 4.6056, Ground Truth: 0\n",
      "cross_p7s1_cycle_353.wav => Predicted: 0, Prob: 4.6117, Ground Truth: 0\n",
      "cross_p7s1_cycle_355.wav => Predicted: 0, Prob: 4.5960, Ground Truth: 0\n",
      "cross_p7s1_cycle_359.wav => Predicted: 0, Prob: 4.5978, Ground Truth: 0\n",
      "cross_p7s1_cycle_361.wav => Predicted: 0, Prob: 4.6037, Ground Truth: 0\n",
      "cross_p7s1_cycle_363.wav => Predicted: 0, Prob: 4.5980, Ground Truth: 0\n",
      "cross_p7s1_cycle_365.wav => Predicted: 0, Prob: 4.5964, Ground Truth: 0\n",
      "cross_p7s1_cycle_367.wav => Predicted: 0, Prob: 4.6176, Ground Truth: 0\n",
      "cross_p7s1_cycle_369.wav => Predicted: 0, Prob: 4.5985, Ground Truth: 0\n",
      "cross_p7s1_cycle_371.wav => Predicted: 0, Prob: 4.6060, Ground Truth: 0\n",
      "cross_p7s1_cycle_373.wav => Predicted: 0, Prob: 4.5673, Ground Truth: 0\n",
      "cross_p7s1_cycle_375.wav => Predicted: 0, Prob: 4.5998, Ground Truth: 0\n",
      "cross_p7s1_cycle_382.wav => Predicted: 0, Prob: 3.1192, Ground Truth: 0\n",
      "cross_p7s1_cycle_384.wav => Predicted: 0, Prob: 4.5605, Ground Truth: 0\n",
      "cross_p7s1_cycle_386.wav => Predicted: 0, Prob: 4.5981, Ground Truth: 0\n",
      "cross_p7s1_cycle_388.wav => Predicted: 0, Prob: 4.5969, Ground Truth: 0\n",
      "cross_p7s1_cycle_390.wav => Predicted: 0, Prob: 4.5982, Ground Truth: 0\n",
      "cross_p7s1_cycle_392.wav => Predicted: 0, Prob: 4.5315, Ground Truth: 0\n",
      "cross_p7s1_cycle_394.wav => Predicted: 0, Prob: 4.5751, Ground Truth: 0\n",
      "cross_p7s1_cycle_396.wav => Predicted: 0, Prob: 4.5956, Ground Truth: 0\n",
      "cross_p7s1_cycle_398.wav => Predicted: 0, Prob: 4.5991, Ground Truth: 0\n",
      "cross_p7s1_cycle_402.wav => Predicted: 0, Prob: 4.5978, Ground Truth: 0\n",
      "cross_p7s1_cycle_404.wav => Predicted: 0, Prob: 4.6205, Ground Truth: 0\n",
      "cross_p7s1_cycle_406.wav => Predicted: 0, Prob: 4.6191, Ground Truth: 0\n",
      "cross_p7s1_cycle_408.wav => Predicted: 0, Prob: 4.5509, Ground Truth: 0\n",
      "cross_p7s1_cycle_410.wav => Predicted: 0, Prob: 4.5988, Ground Truth: 0\n",
      "cross_p7s1_cycle_417.wav => Predicted: 0, Prob: 4.5778, Ground Truth: 0\n",
      "cross_p7s1_cycle_419.wav => Predicted: 0, Prob: 5.3644, Ground Truth: 0\n",
      "cross_p7s1_cycle_421.wav => Predicted: 0, Prob: 2.6166, Ground Truth: 0\n",
      "cross_p7s1_cycle_423.wav => Predicted: 1, Prob: 4.5162, Ground Truth: 0\n",
      "cross_p7s1_cycle_425.wav => Predicted: 0, Prob: 5.3723, Ground Truth: 0\n",
      "cross_p7s1_cycle_427.wav => Predicted: 0, Prob: 4.5964, Ground Truth: 0\n",
      "cross_p7s1_cycle_429.wav => Predicted: 0, Prob: 5.4954, Ground Truth: 0\n",
      "cross_p7s1_cycle_431.wav => Predicted: 1, Prob: 4.6693, Ground Truth: 0\n",
      "cross_p7s1_cycle_433.wav => Predicted: 0, Prob: 5.4838, Ground Truth: 0\n",
      "cross_p7s1_cycle_435.wav => Predicted: 0, Prob: 5.5034, Ground Truth: 0\n",
      "cross_p7s1_cycle_437.wav => Predicted: 0, Prob: 5.3433, Ground Truth: 0\n",
      "cross_p7s1_cycle_439.wav => Predicted: 0, Prob: 4.6003, Ground Truth: 0\n",
      "cross_p7s1_cycle_441.wav => Predicted: 0, Prob: 5.8799, Ground Truth: 0\n",
      "cross_p7s1_cycle_443.wav => Predicted: 0, Prob: 5.3436, Ground Truth: 0\n",
      "cross_p7s1_cycle_445.wav => Predicted: 0, Prob: 1.6099, Ground Truth: 0\n",
      "cross_p7s1_cycle_447.wav => Predicted: 0, Prob: 4.5971, Ground Truth: 0\n",
      "cross_p7s1_cycle_449.wav => Predicted: 0, Prob: 4.5623, Ground Truth: 0\n",
      "cross_p7s1_cycle_451.wav => Predicted: 0, Prob: 5.8769, Ground Truth: 0\n",
      "cross_p7s1_cycle_453.wav => Predicted: 0, Prob: 5.3637, Ground Truth: 0\n",
      "cross_p7s1_cycle_455.wav => Predicted: 1, Prob: 4.3269, Ground Truth: 0\n",
      "cross_p7s1_cycle_457.wav => Predicted: 0, Prob: 3.2058, Ground Truth: 0\n",
      "cross_p7s1_cycle_459.wav => Predicted: 0, Prob: 5.8676, Ground Truth: 0\n",
      "cross_p7s1_cycle_463.wav => Predicted: 0, Prob: 5.3833, Ground Truth: 0\n",
      "cross_p7s1_cycle_465.wav => Predicted: 0, Prob: 4.3221, Ground Truth: 0\n",
      "cross_p7s1_cycle_467.wav => Predicted: 0, Prob: 5.3727, Ground Truth: 0\n",
      "cross_p7s1_cycle_469.wav => Predicted: 1, Prob: 4.4879, Ground Truth: 0\n",
      "cross_p7s1_cycle_471.wav => Predicted: 0, Prob: 4.5553, Ground Truth: 0\n",
      "cross_p7s1_cycle_473.wav => Predicted: 0, Prob: 5.5063, Ground Truth: 0\n",
      "cross_p7s1_cycle_475.wav => Predicted: 0, Prob: 4.6155, Ground Truth: 0\n",
      "cross_p7s1_cycle_477.wav => Predicted: 0, Prob: 4.5849, Ground Truth: 0\n",
      "cross_p7s1_cycle_479.wav => Predicted: 0, Prob: 5.3660, Ground Truth: 0\n",
      "cross_p7s1_cycle_481.wav => Predicted: 0, Prob: 4.0926, Ground Truth: 0\n",
      "cross_p7s1_cycle_483.wav => Predicted: 0, Prob: 5.3765, Ground Truth: 0\n",
      "cross_p7s1_cycle_485.wav => Predicted: 0, Prob: 5.4509, Ground Truth: 0\n",
      "cross_p7s1_cycle_487.wav => Predicted: 0, Prob: 4.5861, Ground Truth: 0\n",
      "cross_p7s1_cycle_489.wav => Predicted: 0, Prob: 5.8732, Ground Truth: 0\n",
      "cross_p7s1_cycle_491.wav => Predicted: 0, Prob: 5.6483, Ground Truth: 0\n",
      "cross_p7s1_cycle_493.wav => Predicted: 0, Prob: 5.3875, Ground Truth: 0\n",
      "cross_p7s1_cycle_495.wav => Predicted: 0, Prob: 5.4790, Ground Truth: 0\n",
      "cross_p7s1_cycle_497.wav => Predicted: 0, Prob: 4.5731, Ground Truth: 0\n",
      "cross_p7s1_cycle_499.wav => Predicted: 0, Prob: 4.5343, Ground Truth: 0\n",
      "cross_p7s1_cycle_501.wav => Predicted: 0, Prob: 4.5712, Ground Truth: 0\n",
      "cross_p7s1_cycle_503.wav => Predicted: 1, Prob: 4.4919, Ground Truth: 0\n",
      "cross_p7s1_cycle_509.wav => Predicted: 0, Prob: 4.5746, Ground Truth: 0\n",
      "cross_p7s1_cycle_511.wav => Predicted: 0, Prob: 4.5751, Ground Truth: 0\n",
      "cross_p7s1_cycle_513.wav => Predicted: 0, Prob: 4.6111, Ground Truth: 0\n",
      "cross_p7s1_cycle_515.wav => Predicted: 0, Prob: 4.5208, Ground Truth: 0\n",
      "cross_p7s1_cycle_517.wav => Predicted: 0, Prob: 4.6191, Ground Truth: 0\n",
      "cross_p7s1_cycle_519.wav => Predicted: 0, Prob: 5.8659, Ground Truth: 0\n",
      "cross_p7s1_cycle_521.wav => Predicted: 0, Prob: 4.6161, Ground Truth: 0\n",
      "cross_p7s1_cycle_523.wav => Predicted: 0, Prob: 4.5671, Ground Truth: 0\n",
      "cross_p7s1_cycle_525.wav => Predicted: 0, Prob: 4.6130, Ground Truth: 0\n",
      "cross_p7s1_cycle_529.wav => Predicted: 0, Prob: 4.6114, Ground Truth: 0\n",
      "cross_p7s1_cycle_531.wav => Predicted: 0, Prob: 4.6105, Ground Truth: 0\n",
      "cross_p7s1_cycle_533.wav => Predicted: 0, Prob: 4.6085, Ground Truth: 0\n",
      "cross_p7s1_cycle_535.wav => Predicted: 0, Prob: 5.6267, Ground Truth: 0\n",
      "cross_p7s1_cycle_537.wav => Predicted: 0, Prob: 4.5746, Ground Truth: 0\n",
      "cross_p7s1_cycle_539.wav => Predicted: 0, Prob: 4.5967, Ground Truth: 0\n",
      "cross_p7s1_cycle_541.wav => Predicted: 0, Prob: 4.6111, Ground Truth: 0\n",
      "cross_p7s1_cycle_543.wav => Predicted: 0, Prob: 4.6128, Ground Truth: 0\n",
      "cross_p7s1_cycle_545.wav => Predicted: 0, Prob: 3.1343, Ground Truth: 0\n",
      "cross_p7s1_cycle_547.wav => Predicted: 0, Prob: 4.6157, Ground Truth: 0\n",
      "cross_p7s1_cycle_549.wav => Predicted: 0, Prob: 4.6120, Ground Truth: 0\n",
      "cross_p7s1_cycle_553.wav => Predicted: 0, Prob: 4.6132, Ground Truth: 0\n",
      "cross_p7s1_cycle_555.wav => Predicted: 0, Prob: 4.6159, Ground Truth: 0\n",
      "cross_p7s1_cycle_557.wav => Predicted: 0, Prob: 4.5772, Ground Truth: 0\n",
      "cross_p7s1_cycle_559.wav => Predicted: 0, Prob: 3.1304, Ground Truth: 0\n",
      "cross_p7s1_cycle_561.wav => Predicted: 0, Prob: 4.6110, Ground Truth: 0\n",
      "cross_p7s1_cycle_563.wav => Predicted: 0, Prob: 4.6057, Ground Truth: 0\n",
      "cross_p7s1_cycle_565.wav => Predicted: 0, Prob: 4.6123, Ground Truth: 0\n",
      "cross_p7s1_cycle_567.wav => Predicted: 0, Prob: 4.6122, Ground Truth: 0\n",
      "cross_p7s1_cycle_569.wav => Predicted: 0, Prob: 5.3595, Ground Truth: 0\n",
      "cross_p7s1_cycle_571.wav => Predicted: 0, Prob: 4.6121, Ground Truth: 0\n",
      "cross_p7s1_cycle_573.wav => Predicted: 0, Prob: 4.6167, Ground Truth: 0\n",
      "cross_p7s1_cycle_575.wav => Predicted: 0, Prob: 4.6115, Ground Truth: 0\n",
      "cross_p7s1_cycle_577.wav => Predicted: 0, Prob: 3.1036, Ground Truth: 0\n",
      "cross_p7s1_cycle_581.wav => Predicted: 0, Prob: 4.6147, Ground Truth: 0\n",
      "cross_p7s1_cycle_583.wav => Predicted: 0, Prob: 4.6110, Ground Truth: 0\n",
      "cross_p7s1_cycle_585.wav => Predicted: 0, Prob: 4.6064, Ground Truth: 0\n",
      "cross_p7s1_cycle_587.wav => Predicted: 0, Prob: 4.5728, Ground Truth: 0\n",
      "cross_p7s1_cycle_589.wav => Predicted: 0, Prob: 4.6191, Ground Truth: 0\n",
      "cross_p7s1_cycle_593_anomalous_noise0.wav => Predicted: 2, Prob: 10.5632, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise1.wav => Predicted: 2, Prob: 10.5635, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise10.wav => Predicted: 2, Prob: 10.5663, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise11.wav => Predicted: 2, Prob: 10.5612, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise12.wav => Predicted: 2, Prob: 10.5709, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise13.wav => Predicted: 2, Prob: 9.5073, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise14.wav => Predicted: 2, Prob: 10.5649, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise15.wav => Predicted: 2, Prob: 10.5494, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise16.wav => Predicted: 2, Prob: 10.5522, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise17.wav => Predicted: 2, Prob: 9.9939, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise18.wav => Predicted: 2, Prob: 9.9950, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise19.wav => Predicted: 2, Prob: 9.9879, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise2.wav => Predicted: 2, Prob: 10.5648, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise20.wav => Predicted: 2, Prob: 10.5597, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise21.wav => Predicted: 2, Prob: 10.3396, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise22.wav => Predicted: 2, Prob: 10.5624, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise23.wav => Predicted: 2, Prob: 10.5555, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise24.wav => Predicted: 2, Prob: 10.3179, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise25.wav => Predicted: 2, Prob: 10.3371, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise26.wav => Predicted: 2, Prob: 10.0248, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise27.wav => Predicted: 2, Prob: 10.5864, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise28.wav => Predicted: 2, Prob: 10.5707, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise29.wav => Predicted: 2, Prob: 10.5378, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise3.wav => Predicted: 2, Prob: 10.5614, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise4.wav => Predicted: 2, Prob: 10.5533, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise5.wav => Predicted: 2, Prob: 10.5644, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise6.wav => Predicted: 2, Prob: 10.5572, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise7.wav => Predicted: 2, Prob: 10.5524, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise8.wav => Predicted: 2, Prob: 10.5527, Ground Truth: 2\n",
      "cross_p7s1_cycle_593_anomalous_noise9.wav => Predicted: 2, Prob: 10.5556, Ground Truth: 2\n",
      "cross_p7s1_cycle_595.wav => Predicted: 0, Prob: 5.3709, Ground Truth: 0\n",
      "cross_p7s1_cycle_597.wav => Predicted: 0, Prob: 5.3566, Ground Truth: 0\n",
      "cross_p7s1_cycle_599.wav => Predicted: 0, Prob: 6.7255, Ground Truth: 0\n",
      "cross_p7s1_cycle_601.wav => Predicted: 0, Prob: 5.8736, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_064.wav => Predicted: 0, Prob: 10.0983, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_066.wav => Predicted: 0, Prob: 6.2503, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_068.wav => Predicted: 0, Prob: 7.4279, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_070.wav => Predicted: 0, Prob: 9.3928, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_072.wav => Predicted: 0, Prob: 5.8827, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_074.wav => Predicted: 0, Prob: 4.8133, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_076.wav => Predicted: 0, Prob: 4.8236, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_078.wav => Predicted: 0, Prob: 4.7447, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_080.wav => Predicted: 0, Prob: 4.5988, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_082.wav => Predicted: 0, Prob: 4.8264, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_084.wav => Predicted: 0, Prob: 6.2155, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_086.wav => Predicted: 0, Prob: 6.2308, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_088.wav => Predicted: 0, Prob: 4.5985, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_090.wav => Predicted: 0, Prob: 4.8232, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_092.wav => Predicted: 0, Prob: 7.1602, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_094.wav => Predicted: 0, Prob: 5.4677, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_096.wav => Predicted: 0, Prob: 4.5932, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_098.wav => Predicted: 0, Prob: 4.8253, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_100.wav => Predicted: 0, Prob: 4.8099, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_102.wav => Predicted: 0, Prob: 4.6004, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_104.wav => Predicted: 0, Prob: 6.0889, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_106.wav => Predicted: 0, Prob: 4.5978, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_108.wav => Predicted: 0, Prob: 4.7311, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_110.wav => Predicted: 0, Prob: 6.2320, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_112.wav => Predicted: 0, Prob: 4.6342, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_114.wav => Predicted: 0, Prob: 5.8731, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_116.wav => Predicted: 0, Prob: 7.2391, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_118.wav => Predicted: 0, Prob: 5.8848, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_120.wav => Predicted: 0, Prob: 4.6492, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_122.wav => Predicted: 0, Prob: 9.5100, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_124.wav => Predicted: 0, Prob: 9.7519, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_126.wav => Predicted: 0, Prob: 6.2428, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_128.wav => Predicted: 0, Prob: 4.6364, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_130.wav => Predicted: 0, Prob: 5.8703, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_132.wav => Predicted: 0, Prob: 6.0762, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_134.wav => Predicted: 0, Prob: 6.2413, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_136.wav => Predicted: 0, Prob: 7.2680, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_138.wav => Predicted: 0, Prob: 4.7329, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_140.wav => Predicted: 0, Prob: 4.7426, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_142.wav => Predicted: 0, Prob: 4.6234, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_144.wav => Predicted: 0, Prob: 6.2538, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_146.wav => Predicted: 0, Prob: 4.8113, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_148.wav => Predicted: 0, Prob: 4.6284, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_150.wav => Predicted: 0, Prob: 4.5938, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_152.wav => Predicted: 0, Prob: 5.0080, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_154.wav => Predicted: 0, Prob: 9.5654, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_156.wav => Predicted: 0, Prob: 7.2884, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_158.wav => Predicted: 0, Prob: 9.8227, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_160.wav => Predicted: 0, Prob: 4.6221, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_162.wav => Predicted: 0, Prob: 4.6032, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_164.wav => Predicted: 0, Prob: 4.6259, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_166.wav => Predicted: 0, Prob: 6.1466, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_168.wav => Predicted: 0, Prob: 4.6201, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_170.wav => Predicted: 0, Prob: 7.3932, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_172.wav => Predicted: 2, Prob: 2.8916, Ground Truth: N/A\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_174.wav => Predicted: 0, Prob: 4.5983, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_176.wav => Predicted: 0, Prob: 4.6030, Ground Truth: 0\n",
      "l6s9.95s10.1_P2S2Girders2H2300_cycle_178.wav => Predicted: 0, Prob: 6.1464, Ground Truth: 0\n",
      "l7s10.55_P2S2Girders2H2300_cycle_002.wav => Predicted: 0, Prob: 11.0845, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_004.wav => Predicted: 0, Prob: 11.1618, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_006.wav => Predicted: 0, Prob: 10.9784, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_008.wav => Predicted: 0, Prob: 10.1355, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_010.wav => Predicted: 0, Prob: 10.9649, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_012.wav => Predicted: 0, Prob: 9.7637, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_014.wav => Predicted: 0, Prob: 7.1748, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_016.wav => Predicted: 0, Prob: 10.5201, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_018.wav => Predicted: 0, Prob: 11.1379, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_020.wav => Predicted: 0, Prob: 10.0052, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_022.wav => Predicted: 0, Prob: 11.0797, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_024.wav => Predicted: 0, Prob: 11.1697, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_026.wav => Predicted: 0, Prob: 9.9167, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_028.wav => Predicted: 0, Prob: 10.2862, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_030.wav => Predicted: 0, Prob: 9.9879, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_032.wav => Predicted: 0, Prob: 9.8143, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_034.wav => Predicted: 0, Prob: 10.0026, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_036.wav => Predicted: 0, Prob: 9.9145, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_038.wav => Predicted: 0, Prob: 11.1470, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_040.wav => Predicted: 0, Prob: 9.7763, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_042.wav => Predicted: 0, Prob: 11.1212, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_044.wav => Predicted: 0, Prob: 10.0168, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_046.wav => Predicted: 0, Prob: 10.0163, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_048.wav => Predicted: 0, Prob: 11.0740, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_050.wav => Predicted: 0, Prob: 10.6538, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_052.wav => Predicted: 0, Prob: 7.8433, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_054.wav => Predicted: 0, Prob: 11.1329, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_056.wav => Predicted: 0, Prob: 11.1467, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_058.wav => Predicted: 0, Prob: 10.1843, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_060.wav => Predicted: 0, Prob: 11.1262, Ground Truth: N/A\n",
      "l7s10.55_P2S2Girders2H2300_cycle_062.wav => Predicted: 0, Prob: 11.0467, Ground Truth: N/A\n",
      "P5_6_2S1JoiningH4000_cycle_001.wav => Predicted: 0, Prob: 9.3509, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_003.wav => Predicted: 0, Prob: 4.6151, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_005.wav => Predicted: 0, Prob: 4.6067, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_007.wav => Predicted: 0, Prob: 4.6119, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_009.wav => Predicted: 0, Prob: 4.6055, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_011.wav => Predicted: 0, Prob: 4.6046, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_013.wav => Predicted: 0, Prob: 4.6104, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_015.wav => Predicted: 0, Prob: 4.6075, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_017.wav => Predicted: 0, Prob: 4.6071, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_021.wav => Predicted: 0, Prob: 4.6117, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_023.wav => Predicted: 0, Prob: 5.6142, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_025.wav => Predicted: 0, Prob: 4.6102, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_027.wav => Predicted: 0, Prob: 4.6016, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_029.wav => Predicted: 0, Prob: 4.6111, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_031.wav => Predicted: 0, Prob: 4.6127, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_033.wav => Predicted: 0, Prob: 4.6131, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_035.wav => Predicted: 0, Prob: 4.6045, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_039.wav => Predicted: 0, Prob: 4.6079, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_041.wav => Predicted: 0, Prob: 3.0915, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_043.wav => Predicted: 0, Prob: 4.6111, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_045.wav => Predicted: 0, Prob: 4.6133, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_047.wav => Predicted: 0, Prob: 4.6141, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_049.wav => Predicted: 0, Prob: 4.5995, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_051.wav => Predicted: 0, Prob: 4.6113, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_053.wav => Predicted: 0, Prob: 4.6007, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_056.wav => Predicted: 0, Prob: 4.5871, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_058.wav => Predicted: 0, Prob: 4.6135, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_060.wav => Predicted: 0, Prob: 4.6119, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_062.wav => Predicted: 0, Prob: 4.6155, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_064.wav => Predicted: 0, Prob: 4.6122, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_066.wav => Predicted: 0, Prob: 4.6133, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_068.wav => Predicted: 0, Prob: 4.6053, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_070.wav => Predicted: 0, Prob: 4.6105, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_072.wav => Predicted: 0, Prob: 4.6124, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_076.wav => Predicted: 0, Prob: 5.8830, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_082.wav => Predicted: 0, Prob: 4.6026, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_084.wav => Predicted: 0, Prob: 4.5980, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_086.wav => Predicted: 0, Prob: 4.6122, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_088.wav => Predicted: 0, Prob: 4.5670, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_090.wav => Predicted: 0, Prob: 4.6053, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_092.wav => Predicted: 0, Prob: 4.6142, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_094.wav => Predicted: 0, Prob: 4.6128, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_096.wav => Predicted: 0, Prob: 4.6112, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_098.wav => Predicted: 0, Prob: 4.6067, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_100.wav => Predicted: 0, Prob: 4.6051, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_102.wav => Predicted: 0, Prob: 4.6125, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_104.wav => Predicted: 0, Prob: 4.6103, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_106.wav => Predicted: 0, Prob: 4.5986, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_108.wav => Predicted: 0, Prob: 4.6058, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_110.wav => Predicted: 0, Prob: 4.6033, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_112.wav => Predicted: 0, Prob: 4.6118, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_114.wav => Predicted: 0, Prob: 4.6041, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_116.wav => Predicted: 0, Prob: 4.6149, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_118.wav => Predicted: 0, Prob: 4.6072, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_120.wav => Predicted: 0, Prob: 4.6149, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_122.wav => Predicted: 0, Prob: 4.6062, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_124.wav => Predicted: 0, Prob: 4.6061, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_126.wav => Predicted: 0, Prob: 4.6065, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_128.wav => Predicted: 0, Prob: 4.6154, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_130.wav => Predicted: 0, Prob: 4.6040, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_132.wav => Predicted: 0, Prob: 4.6129, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_134.wav => Predicted: 0, Prob: 4.6125, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_136.wav => Predicted: 0, Prob: 4.6031, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_138.wav => Predicted: 0, Prob: 4.6073, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_140.wav => Predicted: 0, Prob: 4.6067, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_142.wav => Predicted: 0, Prob: 4.6156, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_144.wav => Predicted: 0, Prob: 4.6028, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_146.wav => Predicted: 0, Prob: 4.6042, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_150.wav => Predicted: 0, Prob: 4.6138, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_152.wav => Predicted: 0, Prob: 4.6124, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_154.wav => Predicted: 0, Prob: 4.6139, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_156.wav => Predicted: 0, Prob: 4.6058, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_158.wav => Predicted: 0, Prob: 4.6047, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_160.wav => Predicted: 0, Prob: 4.6040, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_162.wav => Predicted: 0, Prob: 4.6067, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_164.wav => Predicted: 0, Prob: 4.6052, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_166.wav => Predicted: 0, Prob: 4.6120, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_168.wav => Predicted: 0, Prob: 4.6055, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_170.wav => Predicted: 0, Prob: 4.6073, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_172.wav => Predicted: 0, Prob: 4.6048, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_174.wav => Predicted: 0, Prob: 4.6031, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_176.wav => Predicted: 0, Prob: 4.6114, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_178.wav => Predicted: 0, Prob: 4.6014, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_180.wav => Predicted: 0, Prob: 4.6032, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_182.wav => Predicted: 0, Prob: 4.6050, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_184.wav => Predicted: 0, Prob: 4.6059, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_186.wav => Predicted: 0, Prob: 4.6134, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_188.wav => Predicted: 0, Prob: 4.6104, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_190.wav => Predicted: 0, Prob: 4.6148, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_192.wav => Predicted: 0, Prob: 4.6069, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_194.wav => Predicted: 0, Prob: 4.6121, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_196.wav => Predicted: 0, Prob: 4.6112, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_198.wav => Predicted: 0, Prob: 4.6158, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_200.wav => Predicted: 0, Prob: 4.6039, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_202.wav => Predicted: 0, Prob: 4.5999, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_204.wav => Predicted: 0, Prob: 4.6131, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_206.wav => Predicted: 0, Prob: 4.6108, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_208.wav => Predicted: 0, Prob: 4.6031, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_210.wav => Predicted: 0, Prob: 4.6139, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_212.wav => Predicted: 0, Prob: 4.6071, Ground Truth: 0\n",
      "P5_6_2S1JoiningH4000_cycle_214.wav => Predicted: 0, Prob: 4.6130, Ground Truth: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Instantiate classifier\n",
    "Audiocls = Audio_Classification(model_path, config)\n",
    "\n",
    "# Set the folder path\n",
    "folder_path = r\"workspace/esc-50/raw/ESC-50-master/Audio_full_v2\"\n",
    "\n",
    "# Loop over all .wav files\n",
    "for wav_file in Path(folder_path).glob(\"*.wav\"):\n",
    "    wav_path = str(wav_file)\n",
    "    filename = wav_file.name\n",
    "\n",
    "    # Predict\n",
    "    pred_label, pred_prob = Audiocls.predict(wav_path)\n",
    "\n",
    "    # Print with ground truth (gd should be a dict defined elsewhere)\n",
    "    print(f\"{filename} => Predicted: {pred_label}, Prob: {pred_prob:.4f}, Ground Truth: {gd.get(filename, 'N/A')}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-28T11:23:01.412284200Z",
     "start_time": "2025-05-28T11:22:10.882473300Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kechen_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb1a0df39641c41734bdd2d42699ec57167c4cf18fd061cdef52c16cce6262af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
